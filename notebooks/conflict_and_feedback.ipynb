{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with Feedback Analysis using Sentiment Analysis and Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingredient database contains features such as type, colour and taste features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.process_data import get_data\n",
    "\n",
    "# Fetch data\n",
    "ingredient_df = get_data()\n",
    "\n",
    "# Adjust pandas display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Print the specific columns\n",
    "print(ingredient_df[['Category7', 'Texture', 'Taste', 'Colour']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Child Feature Data\n",
    "\n",
    "Generated data on 30 children, including features such as age, gender, favorite_cuisine, and health considerations. These features are known to influence food preferences. Such data could be collected through existing databases. These features paired with the ingredient features could be used to predict whether a new child will like an ingredient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_child_data():\n",
    "    # Function to get feature data on children\n",
    "    return {\n",
    "        \"child1\": {\"age\": 10, \"gender\": \"M\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child2\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"very health conscious\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child3\": {\"age\": 9, \"gender\": \"M\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child4\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child5\": {\"age\": 11, \"gender\": \"M\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child6\": {\"age\": 11, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child7\": {\"age\": 9, \"gender\": \"M\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child8\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"very health conscious\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child9\": {\"age\": 10, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child10\": {\"age\": 11, \"gender\": \"M\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child11\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child12\": {\"age\": 9, \"gender\": \"M\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child13\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Seafood\"},\n",
    "        \"child14\": {\"age\": 10, \"gender\": \"M\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"Seafood\"},\n",
    "        \"child15\": {\"age\": 11, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Seafood\"},\n",
    "        \"child16\": {\"age\": 11, \"gender\": \"M\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Seafood\"},\n",
    "        \"child17\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child18\": {\"age\": 9, \"gender\": \"M\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Seafood\"},\n",
    "        \"child19\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Seafood\"},\n",
    "        \"child20\": {\"age\": 10, \"gender\": \"M\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"BBQ\"},\n",
    "        \"child21\": {\"age\": 10, \"gender\": \"F\", \"health_consideration\": \"very health conscious\", \"favorite_cuisine\": \"BBQ\"},\n",
    "        \"child22\": {\"age\": 9, \"gender\": \"M\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"BBQ\"},\n",
    "        \"child23\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"BBQ\"},\n",
    "        \"child24\": {\"age\": 9, \"gender\": \"M\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"BBQ\"},\n",
    "        \"child25\": {\"age\": 11, \"gender\": \"F\", \"health_consideration\": \"very health conscious\", \"favorite_cuisine\": \"BBQ\"},\n",
    "        \"child26\": {\"age\": 11, \"gender\": \"M\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"BBQ\"},\n",
    "        \"child27\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"moderately health conscious\", \"favorite_cuisine\": \"Seafood\"},\n",
    "        \"child28\": {\"age\": 9, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Seafood\"},\n",
    "        \"child29\": {\"age\": 9, \"gender\": \"M\", \"health_consideration\": \"very health conscious\", \"favorite_cuisine\": \"Italian\"},\n",
    "        \"child30\": {\"age\": 10, \"gender\": \"F\", \"health_consideration\": \"don't care\", \"favorite_cuisine\": \"Italian\"}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Child Preference Data\n",
    "\n",
    "The dataset consists of generated preferences for n children. In a real-world context, such data could be gathered through questionnaires or feedback after meals. For this example, the data is synthesized based on multiple studies that explore factors influencing children's food preferences. Each child is assigned a score for each ingredient, derived from their individual characteristics, and a label indicating whether they like, are neutral towards, or dislike the ingredient. There is also a random element added. While the influence of these factors is not precisely accurate and would require refinement in a real-world setting, they serve as a foundational basis for analysis in this research. The function also splits the data, which will be used to determine if the feedback can predict the rest of the children's preferences.\n",
    "\n",
    "Reference: [Study on children's vegetable preferences](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6173934/)\n",
    "\n",
    "## Add more references when writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "def get_modifiers(\n",
    "    features: Dict[str, Any],\n",
    "    ingredient_row: pd.Series,\n",
    "    health_consideration_modifiers: Dict[str, Dict[str, float]],\n",
    "    favorite_cuisine_modifiers: Dict[str, Dict[str, float]],\n",
    "    taste_modifiers: Dict[str, float],\n",
    "    colour_modifiers: Dict[str, float],\n",
    "    gender_modifiers: Dict[str, float],\n",
    "    age_modifiers: Dict[int, float],\n",
    "    texture_modifiers: Dict[str, float],\n",
    "    other_modifiers: Dict[str, Any],\n",
    "    vegetable_groups: Dict[str, list],\n",
    "    group_probabilities_modifiers: Dict[str, float]\n",
    ") -> float:\n",
    "    health_consideration = features[\"health_consideration\"]\n",
    "    age = features[\"age\"]\n",
    "    gender = features[\"gender\"]\n",
    "    favorite_cuisine = features[\"favorite_cuisine\"]\n",
    "\n",
    "    health_category = ingredient_row[\"Healthy\"]\n",
    "    ingredient_category1 = ingredient_row[\"Category1\"]\n",
    "    taste = ingredient_row[\"Taste\"]\n",
    "    colour = ingredient_row[\"Colour\"]\n",
    "    texture = ingredient_row[\"Texture\"]\n",
    "    ingredient = ingredient_row[\"Category7\"]\n",
    "\n",
    "    health_mod = health_consideration_modifiers[health_consideration][health_category]\n",
    "    favorite_mod = favorite_cuisine_modifiers.get(favorite_cuisine, {}).get(ingredient_category1, 1)\n",
    "    taste_mod = taste_modifiers.get(taste, taste_modifiers[\"Misc\"])\n",
    "    colour_mod = colour_modifiers[colour]\n",
    "    texture_mod = texture_modifiers[texture]\n",
    "    gender_mod = gender_modifiers[gender]\n",
    "    age_mod = age_modifiers[age]\n",
    "\n",
    "    group_name = next((group for group, ingredients in vegetable_groups.items() if ingredient in ingredients), None)\n",
    "    group_mod = group_probabilities_modifiers.get(group_name, 1)\n",
    "\n",
    "    fruit_mod = other_modifiers[\"fruit_factor\"] if ingredient_category1 == \"Fruits and fruit products\" else 1\n",
    "    vegetable_mod = other_modifiers[\"vegetables_factor\"][gender] if ingredient_category1 == \"Vegetables and vegetable products\" else 1\n",
    "    meat_mod = other_modifiers[\"meat_factor\"][gender] if ingredient_category1 == \"Meat and meat products\" else 1\n",
    "    random_mod = random.uniform(other_modifiers[\"random_factor\"][0], other_modifiers[\"random_factor\"][1])\n",
    "\n",
    "    return (health_mod * favorite_mod * taste_mod * colour_mod * gender_mod * age_mod * \n",
    "            texture_mod * group_mod * fruit_mod * vegetable_mod * meat_mod * random_mod)\n",
    "\n",
    "def initialize_children_data(child_data: Dict[str, Dict[str, Any]], ingredient_df: pd.DataFrame, split: float = 0.8, seed: int = None, plot_graphs: bool = False) -> Tuple[Dict[str, Dict[str, list]], Dict[str, Dict[str, list]]]:\n",
    "    random.seed(seed)\n",
    "    children_data = {}\n",
    "    all_scores = []\n",
    "    all_preferences = {\"likes\": [], \"neutral\": [], \"dislikes\": []}\n",
    "\n",
    "    # Factors affecting preferences with modifier values (increased impact)\n",
    "    health_consideration_modifiers = {\n",
    "        \"very health conscious\": {\"healthy\": 1.5, \"average\": 1, \"unhealthy\": 0.5},\n",
    "        \"moderately health conscious\": {\"healthy\": 1.3, \"average\": 1, \"unhealthy\": 0.7},\n",
    "        \"don't care\": {\"healthy\": 0.7, \"average\": 1, \"unhealthy\": 1.3},\n",
    "    }\n",
    "\n",
    "    favorite_cuisine_modifiers = {\n",
    "        \"BBQ\": {\"Meat and meat products\": 1.4},\n",
    "        \"Seafood\": {\"Fish seafood amphibians reptiles and invertebrates\": 1.4},\n",
    "        \"Italian\": {\"Anchovies\": 1.4, \"Aubergines\": 1.4, \"Noodles\": 1.4, \"Pasta plain (not stuffed) uncooked\": 1.4, \"Pasta wholemeal\": 1.4, \"Tomatoes\": 1.4},\n",
    "    }\n",
    "\n",
    "    taste_modifiers = {\n",
    "        \"Sweet\": 1.3,\n",
    "        \"Salty\": 1.3,\n",
    "        \"Sour\": 0.7,\n",
    "        \"Earthy\": 0.7,\n",
    "        \"Misc\": 1,\n",
    "    }\n",
    "\n",
    "    colour_modifiers = {\n",
    "        \"Red\": 1.3,\n",
    "        \"Green\": 1.3,\n",
    "        \"Yellow\": 1.2,\n",
    "        \"Orange\": 1.2,\n",
    "        \"Pink\": 1,\n",
    "        \"Purple\": 1,\n",
    "        \"White\": 0.8,\n",
    "        \"Brown\": 0.8,\n",
    "    }\n",
    "\n",
    "    gender_modifiers = {\n",
    "        \"M\": 0.7,\n",
    "        \"F\": 1.3,\n",
    "    }\n",
    "\n",
    "    age_modifiers = {\n",
    "        9: 0.7,\n",
    "        10: 1,\n",
    "        11: 1.3,\n",
    "    }\n",
    "\n",
    "    texture_modifiers = {\n",
    "        \"Crunchy\": 0.7,\n",
    "        \"Soft\": 1.3,\n",
    "        \"Soft/Crunchy\": 0.6,\n",
    "        \"Firm\": 1.3,\n",
    "        \"Leafy\": 1,\n",
    "        \"Grainy\": 1,\n",
    "        \"Liquid\": 1,\n",
    "        \"Powdery\": 1,\n",
    "        \"Creamy\": 1,\n",
    "        \"Hard\": 1,\n",
    "    }\n",
    "\n",
    "    other_modifiers = {\n",
    "        \"fruit_factor\": 1.3,\n",
    "        \"vegetables_factor\": {\"M\": 0.7, \"F\": 1.3},\n",
    "        \"meat_factor\": {\"M\": 1.3, \"F\": 0.7},\n",
    "        \"random_factor\": [0.7, 1.3]\n",
    "    }\n",
    "\n",
    "    vegetable_groups = {\n",
    "        \"Group A\": [\"Tomatoes\", \"Sweet corn\", \"Sweet potatoes\", \"Carrots\"],\n",
    "        \"Group B\": [\"Onions\", \"Spring onions\", \"Pepper\"],\n",
    "        \"Group C\": [\"Cauliflowers\"],\n",
    "        \"Group D\": [\"Courgettes\", \"Spinaches\", \"Curly kales\", \"Peas\"],\n",
    "        \"Group E\": [\"Beetroots\", \"Lettuces (generic)\", \"Broccoli\"],\n",
    "        \"Group F\": [\"Aubergines\", \"Cucumber\", \"White cabbage\", \"Savoy cabbages\", \"Red cabbage\", \"Runner beans (with pods)\"],\n",
    "    }\n",
    "\n",
    "    group_probabilities_modifiers = {\n",
    "        \"Group A\": 1.4,\n",
    "        \"Group B\": 1.3,\n",
    "        \"Group C\": 0.7, \n",
    "        \"Group D\": 1, \n",
    "        \"Group E\": 0.9, \n",
    "        \"Group F\": 0.9 \n",
    "    }\n",
    "\n",
    "    for child_key, features in child_data.items():\n",
    "        preferences = {\"likes\": [], \"neutral\": [], \"dislikes\": []}\n",
    "        child_scores = []\n",
    "\n",
    "        for _, row in ingredient_df.iterrows():\n",
    "            score = get_modifiers(features, row, health_consideration_modifiers, favorite_cuisine_modifiers, taste_modifiers,\n",
    "                                  colour_modifiers, gender_modifiers, age_modifiers, texture_modifiers, other_modifiers,\n",
    "                                  vegetable_groups, group_probabilities_modifiers)\n",
    "            child_scores.append((row[\"Category7\"], score))\n",
    "\n",
    "        child_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        all_scores.extend(child_scores)\n",
    "\n",
    "        num_ingredients = len(child_scores)\n",
    "        num_likes = int(0.6 * num_ingredients)\n",
    "        num_neutral = int(0.2 * num_ingredients)\n",
    "        num_dislikes = num_ingredients - num_likes - num_neutral\n",
    "\n",
    "        preferences[\"likes\"] = [ingredient for ingredient, _ in child_scores[:num_likes]]\n",
    "        preferences[\"neutral\"] = [ingredient for ingredient, _ in child_scores[num_likes:num_likes + num_neutral]]\n",
    "        preferences[\"dislikes\"] = [ingredient for ingredient, _ in child_scores[num_likes + num_neutral:]]\n",
    "\n",
    "        all_preferences[\"likes\"].extend(preferences[\"likes\"])\n",
    "        all_preferences[\"neutral\"].extend(preferences[\"neutral\"])\n",
    "        all_preferences[\"dislikes\"].extend(preferences[\"dislikes\"])\n",
    "\n",
    "        children_data[child_key] = preferences\n",
    "\n",
    "    all_data = {}\n",
    "\n",
    "    for child_key, preferences in children_data.items():\n",
    "        known_preferences = {\"likes\": [], \"neutral\": [], \"dislikes\": []}\n",
    "        unknown_preferences = {\"likes\": [], \"neutral\": [], \"dislikes\": []}\n",
    "\n",
    "        for category in [\"likes\", \"neutral\", \"dislikes\"]:\n",
    "            total_items = len(preferences[category])\n",
    "            split_index = int(total_items * split)\n",
    "            known_preferences[category] = preferences[category][:split_index]\n",
    "            unknown_preferences[category] = preferences[category][split_index:]\n",
    "\n",
    "        all_data[child_key] = {\n",
    "            \"known\": known_preferences,\n",
    "            \"unknown\": unknown_preferences\n",
    "        }\n",
    "\n",
    "    if plot_graphs:\n",
    "        plot_histograms(all_scores, all_preferences)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "def plot_histograms(scores: list, preferences: Dict[str, list]) -> None:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist([score for ingredient, score in scores if ingredient in preferences[\"likes\"]], bins=20, color='green', alpha=0.7, label='Like')\n",
    "    plt.title('Like Scores')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.hist([score for ingredient, score in scores if ingredient in preferences[\"neutral\"]], bins=20, color='blue', alpha=0.7, label='Neutral')\n",
    "    plt.title('Neutral Scores')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.hist([score for ingredient, score in scores if ingredient in preferences[\"dislikes\"]], bins=20, color='red', alpha=0.7, label='Dislike')\n",
    "    plt.title('Dislike Scores')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.preferences.data_utils import get_child_data, initialize_children_data\n",
    "from utils.process_data import get_data\n",
    "\n",
    "ingredient_df = get_data()\n",
    "\n",
    "all_preferences = initialize_children_data(get_child_data(), ingredient_df, seed=None, plot_graphs=False)\n",
    "\n",
    "print(all_preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Child Feedback\n",
    "\n",
    "The comments are designed to test the sentiment analysis capabilities of language models and determine if child preferences can be identified through feedback. The comments discuss multiple ingredients, allowing us to evaluate whether the sentiment towards each ingredient can be accurately measured through relatively simple sentiment analysis. Additionally, they help monitor how satisfaction with the meal plan will evolve over time. In reality, the comments wouldn't be as perfectly structured as they are here, but this serves as a good starting point. Feedback is provided based on the known and unknown preferences of the child. These comments will then be used to update the known preference list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "def get_feedback(preferences: Dict[str, Dict[str, list]], ingredient_list: list, seed=None):\n",
    "    # Function to get feedback on meal plan which gives randomized comments on the ingredients for each child.\n",
    "    # The function also sometimes doesn't provide feedback for some children. \n",
    "    comments = [\n",
    "        (\"Didn't like the {} and {} in the dish, but the {} was tasty.\", [\"dislikes\", \"dislikes\", \"likes\"]),\n",
    "        (\"Did not enjoy the {} and {}.\", [\"dislikes\", \"dislikes\"]),\n",
    "        (\"Enjoyed the {} and {}, but was okay with the {}.\", [\"likes\", \"likes\", \"neutral\"]),\n",
    "        (\"Loved the {}, but didn't like the {} and {}.\", [\"likes\", \"dislikes\", \"dislikes\"]),\n",
    "        (\"The {} was great, but the {} was average.\", [\"likes\", \"neutral\"]),\n",
    "        (\"Didn't enjoy the {}, but the {} was average..\", [\"dislikes\", \"neutral\"]),\n",
    "        (\"Loved the {} and {}, but not the {}.\", [\"likes\", \"likes\", \"dislikes\"]),\n",
    "        (\"Loved the {}, but the {} was not appealing.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"Enjoyed the {}, but the {} was not liked.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"Didn't like the {}, {} and {} together.\", [\"dislikes\", \"dislikes\", \"dislikes\"]),\n",
    "        (\"Really liked the {} with {} and the {} was tasty.\", [\"likes\", \"likes\", \"likes\"]),\n",
    "        (\"Didn't like the {} in the dish, but the {} was fine.\", [\"dislikes\", \"neutral\"]),\n",
    "        (\"Enjoyed the {} and {}, but not the {}.\", [\"likes\", \"likes\", \"dislikes\"]),\n",
    "        (\"Didn't like the {} and {}.\", [\"dislikes\", \"dislikes\"]),\n",
    "        (\"The {} and {} were amazing, but didn't enjoy the {} much.\", [\"likes\", \"likes\", \"dislikes\"]),\n",
    "        (\"Loved the {} and {}, but not the {}.\", [\"likes\", \"likes\", \"dislikes\"]),\n",
    "        (\"Didn't enjoy the {} much, but the {} was okay.\", [\"dislikes\", \"neutral\"]),\n",
    "        (\"The {} and {} dish was great.\", [\"likes\", \"likes\"]),\n",
    "        (\"Didn't like the {}.\", [\"dislikes\"]),\n",
    "        (\"Enjoyed the {} and {}.\", [\"likes\", \"likes\"]),\n",
    "        (\"Loved the {} and {}.\", [\"likes\", \"likes\"]),\n",
    "        (\"Didn't like the {} and the {}.\", [\"dislikes\", \"dislikes\"]),\n",
    "        (\"Enjoyed the {} and {}, but the {} was okay.\", [\"likes\", \"likes\", \"neutral\"]),\n",
    "        (\"Didn't like the {} and {} in the dish.\", [\"dislikes\", \"dislikes\"]),\n",
    "        (\"Didn't like the {}, but the {} was okay.\", [\"dislikes\", \"neutral\"]),\n",
    "        (\"Enjoyed the {} and {}, but didn't like the {}.\", [\"likes\", \"likes\", \"dislikes\"]),\n",
    "        (\"Didn't like the {}.\", [\"dislikes\"]),\n",
    "        (\"Loved the {} and {}, but the {} was not liked.\", [\"likes\", \"likes\", \"dislikes\"]),\n",
    "        (\"Didn't like the {}, but the {} was okay.\", [\"dislikes\", \"neutral\"]),\n",
    "        (\"Enjoyed the {} and {}.\", [\"likes\", \"likes\"]),\n",
    "        (\"Liked the {} but not the {}.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"The {} was fine, but the {} wasn't good.\", [\"neutral\", \"dislikes\"]),\n",
    "        (\"The {} and {} were great, but the {} was not.\", [\"likes\", \"likes\", \"dislikes\"]),\n",
    "        (\"The {} was tasty, but the {} wasn't.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"The {} was okay, but the {} wasn't appealing.\", [\"neutral\", \"dislikes\"]),\n",
    "        (\"Didn't like the {}, but the {} was good.\", [\"dislikes\", \"likes\"]),\n",
    "        (\"The {} and {} were okay, but the {} wasn't.\", [\"neutral\", \"neutral\", \"dislikes\"]),\n",
    "        (\"Really liked the {}, but the {} was too strong.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"Enjoyed the {}, but the {} was too bland.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"The {} was fine, but the {} needed more flavor.\", [\"neutral\", \"dislikes\"]),\n",
    "        (\"Loved the {}, but the {} was not good.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"Didn't enjoy the {}, but the {} was okay.\", [\"dislikes\", \"neutral\"]),\n",
    "        (\"The {} was good, but the {} was not to my taste.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"Enjoyed the {}, but the {} was too overpowering.\", [\"likes\", \"dislikes\"]),\n",
    "        (\"The {} was delicious, but the {} wasn't enjoyable.\", [\"likes\", \"dislikes\"])\n",
    "    ]\n",
    "    \n",
    "\n",
    "    random.seed(seed)\n",
    "    feedback = {}\n",
    "\n",
    "    for child, prefs in preferences.items():  # Iterate over each child and their preferences\n",
    "        \n",
    "        # Combine known and unknown preferences for likes, neutral, and dislikes\n",
    "        available_ingredients = {\n",
    "            \"likes\": prefs['known']['likes'] + prefs['unknown']['likes'],\n",
    "            \"neutral\": prefs['known']['neutral'] + prefs['unknown']['neutral'],\n",
    "            \"dislikes\": prefs['known']['dislikes'] + prefs['unknown']['dislikes'],\n",
    "        }\n",
    "\n",
    "        valid_comments = []  # Initialize the list of valid comments\n",
    "\n",
    "        # Iterate over each comment template and its corresponding feedback types\n",
    "        for comment_template, feedback_types in comments:\n",
    "            matched_ingredients = []  # Initialize the list of matched ingredients\n",
    "            used_ingredients = set()  # Initialize the set of used ingredients\n",
    "\n",
    "            # Match ingredients according to feedback types\n",
    "            for feedback_type in feedback_types:\n",
    "                for category in available_ingredients:\n",
    "                    if feedback_type in category:  # Check if the feedback type matches the category\n",
    "                        # List possible ingredients not yet used\n",
    "                        possible_ingredients = [ingredient for ingredient in ingredient_list if ingredient in available_ingredients[category] and ingredient not in used_ingredients]\n",
    "                        if possible_ingredients:  # If there are possible ingredients\n",
    "                            chosen_ingredient = random.choice(possible_ingredients)  # Randomly select an ingredient\n",
    "                            matched_ingredients.append(chosen_ingredient)  # Add the chosen ingredient to the matched list\n",
    "                            used_ingredients.add(chosen_ingredient)  # Mark the ingredient as used\n",
    "                            break  # Break after finding a valid ingredient\n",
    "\n",
    "            # Check if we have matched the required number of ingredients\n",
    "            if len(matched_ingredients) == len(feedback_types):\n",
    "                valid_comments.append((comment_template, matched_ingredients, feedback_types))  # Add to valid comments if matches found\n",
    "\n",
    "        # Select a random valid comment from the list of valid comments\n",
    "        if valid_comments:\n",
    "            comment_template, matched_ingredients, feedback_types = random.choice(valid_comments)  # Randomly select a valid comment\n",
    "            comment = comment_template.format(*matched_ingredients)  # Format the comment with matched ingredients\n",
    "            correct_action = {ingredient: feedback_types[idx] for idx, ingredient in enumerate(matched_ingredients)}\n",
    "            feedback[child] = {\"comment\": comment, \"correct_action\": correct_action}  # Add the comment to the child's feedback\n",
    "\n",
    "    return feedback  # Return the feedback dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import get_child_data, initialize_children_data, get_feedback\n",
    "from utils.process_data import get_data\n",
    "\n",
    "ingredient_df = get_data()\n",
    "preferences = initialize_children_data(get_child_data(), ingredient_df, seed=None, plot_graphs=False, split = 0.2)\n",
    "\n",
    "# print(\"Known:\", preferences['child1']['known'])\n",
    "# print(\"Unknown:\", preferences['child1']['unknown'])\n",
    "\n",
    "# # Example usage       # like             # dislike              # like                         # dislike                     # dislike\n",
    "ingredient_list = ['Sweet potatoes', 'Rice grain brown', 'Cow ox or bull fresh meat', 'Wheat bread and rolls brown or wholemeal', 'Aubergines']\n",
    "                # [like, dislike, like, like, dislike]\n",
    "feedback = get_feedback(preferences, ingredient_list, seed=None)\n",
    "\n",
    "for child, details in feedback.items():\n",
    "    print(f\"{child}: {details['comment']}\")\n",
    "    print(details['correct_action'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sentiment analysis\n",
    "\n",
    "Use to take comments and update preferences, by finding what ingredients they speak positively about and don't "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_preferences_and_update_data(preferences, feedback, ingredient_list, plot_confusion_matrix=False):\n",
    "    changes = []\n",
    "    incorrect_comments = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    # Mapping for confusion matrix\n",
    "    label_mapping = {'likes': 0, 'neutral': 1, 'dislikes': 2}\n",
    "    \n",
    "    # Iterate over each child's feedback\n",
    "    for child, fb in feedback.items():\n",
    "        # Split comments into sentences based on punctuation\n",
    "        comments = re.split(r'[,.!?]', fb[\"comment\"].lower())\n",
    "        correct_action = fb[\"correct_action\"]\n",
    "        \n",
    "        # Analyze each comment's sentiment\n",
    "        for sentence in comments:\n",
    "            if sentence.strip():  # Check if the sentence is not empty\n",
    "                pred_label = analyze_sentiment(sentence.strip())\n",
    "                \n",
    "                # Check for mentions of each ingredient in the sentence\n",
    "                for ingredient in ingredient_list:\n",
    "                    if ingredient.lower() in sentence:\n",
    "                        change = {\"child\": child, \"ingredient\": ingredient, \"change\": \"\"}\n",
    "                        \n",
    "                        # Determine the appropriate category based on polarity\n",
    "                        if pred_label == 'likes':  \n",
    "                            if ingredient not in preferences[child]['known'][\"likes\"]:\n",
    "                                preferences[child]['known'][\"likes\"].append(ingredient)\n",
    "                                change[\"change\"] = \"added to likes\"\n",
    "                        elif pred_label == 'dislikes':\n",
    "                            if ingredient not in preferences[child]['known'][\"dislikes\"]:\n",
    "                                preferences[child]['known'][\"dislikes\"].append(ingredient)\n",
    "                                change[\"change\"] = \"added to dislikes\"\n",
    "                        else:\n",
    "                            pred_label = 'neutral'\n",
    "                            if ingredient not in preferences[child]['known'][\"neutral\"]:\n",
    "                                preferences[child]['known'][\"neutral\"].append(ingredient)\n",
    "                                change[\"change\"] = \"added to neutral\"\n",
    "                        \n",
    "                        # Remove ingredient from other lists\n",
    "                        if change[\"change\"]:\n",
    "                            if change[\"change\"] != \"added to likes\" and ingredient in preferences[child]['known'][\"likes\"]:\n",
    "                                preferences[child]['known'][\"likes\"].remove(ingredient)\n",
    "                                change[\"change\"] += \", removed from likes\"\n",
    "                            if change[\"change\"] != \"added to dislikes\" and ingredient in preferences[child]['known'][\"dislikes\"]:\n",
    "                                preferences[child]['known']['dislikes'].remove(ingredient)\n",
    "                                change[\"change\"] += \", removed from dislikes\"\n",
    "                            if change[\"change\"] != \"added to neutral\" and ingredient in preferences[child]['known'][\"neutral\"]:\n",
    "                                preferences[child]['known'][\"neutral\"].remove(ingredient)\n",
    "                                change[\"change\"] += \", removed from neutral\"\n",
    "                            \n",
    "                            changes.append(change)\n",
    "                        \n",
    "                        true_labels.append(correct_action[ingredient])\n",
    "                        pred_labels.append(pred_label)\n",
    "                        \n",
    "                        # Check if the prediction was incorrect\n",
    "                        if pred_label != correct_action[ingredient]:\n",
    "                            incorrect_comments.append({\n",
    "                                \"child\": child,\n",
    "                                \"comment\": sentence,\n",
    "                                \"predicted\": pred_label,\n",
    "                                \"actual\": correct_action[ingredient]\n",
    "                            })\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct_actions = sum(1 for true, pred in zip(true_labels, pred_labels) if true == pred)\n",
    "    total_actions = len(true_labels)\n",
    "    accuracy = correct_actions / total_actions if total_actions > 0 else 0\n",
    "\n",
    "    # Plot confusion matrix if flag is set\n",
    "    if plot_confusion_matrix and total_actions > 0:\n",
    "        cm = confusion_matrix([label_mapping[label] for label in true_labels], \n",
    "                              [label_mapping[label] for label in pred_labels], \n",
    "                              labels=[0, 1, 2])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['likes', 'neutral', 'dislikes'])\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    return changes, preferences, accuracy, incorrect_comments\n",
    "\n",
    "\n",
    "# Function to display the changes made to children's preferences\n",
    "def display_changes(changes):\n",
    "    for change in changes:\n",
    "        print(\"Action Taken:\\n\")\n",
    "        print(f\"Child {change['child']} had {change['ingredient']} {change['change']}.\")\n",
    "        \n",
    "# Function to display incorrect comments and reasons\n",
    "def display_incorrect_comments(incorrect_comments):\n",
    "    for comment in incorrect_comments:\n",
    "        print(f\"Child {comment['child']} commented: '{comment['comment']}'\")\n",
    "        print(f\"Predicted: {comment['predicted']}, Actual: {comment['actual']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Blob Method\n",
    "\n",
    "Fast but doesn't completley capture all the context around ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to analyze the sentiment of a comment\n",
    "def analyze_sentiment(comment):\n",
    "    # Create a TextBlob object from the comment\n",
    "    analysis = TextBlob(comment)\n",
    "    # Get the polarity of the comment's sentiment (-1 to 1)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    # Determine sentiment category\n",
    "    if polarity > 0.1:\n",
    "        return 'likes'\n",
    "    elif polarity < -0.1:\n",
    "        return 'dislikes'\n",
    "    else:\n",
    "        return 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import get_child_data, initialize_children_data, get_feedback\n",
    "from utils.process_data import get_data\n",
    "\n",
    "ingredient_df = get_data()\n",
    "preferences = initialize_children_data(get_child_data(), ingredient_df, seed=None, plot_graphs=False, split = 0.2)\n",
    "\n",
    "# # Example usage       # like             # dislike              # like                         # dislike                     # dislike\n",
    "ingredient_list = ['Sweet potatoes', 'Rice grain brown', 'Cow ox or bull fresh meat', 'Wheat bread and rolls brown or wholemeal', 'Aubergines']\n",
    "                # [like, dislike, like, like, dislike]\n",
    "feedback = get_feedback(preferences, ingredient_list, seed=None)\n",
    "\n",
    "# Extract preferences and update data\n",
    "changes, preferences, accuracy, incorrect_comments = extract_preferences_and_update_data(preferences, feedback, ingredient_list, plot_confusion_matrix=True)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "# Display the changes\n",
    "# for change in changes:\n",
    "#     print(f\"Child {change['child']} had {change['ingredient']} {change['change']}.\")\n",
    "\n",
    "display_incorrect_comments(incorrect_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Function to analyze the sentiment of a comment using VADER\n",
    "def analyze_sentiment(comment):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    vs = analyzer.polarity_scores(comment)\n",
    "    \n",
    "    # Remove the 'compound' score from the dictionary\n",
    "    vs.pop('compound')\n",
    "\n",
    "    # Determine sentiment category based on the highest probability\n",
    "    sentiment = max(vs, key=vs.get)\n",
    "    if sentiment == 'pos':\n",
    "        return 'likes'\n",
    "    elif sentiment == 'neg':\n",
    "        return 'dislikes'\n",
    "    else:\n",
    "        return 'neutral'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import get_child_data, initialize_children_data, get_feedback\n",
    "from utils.process_data import get_data\n",
    "\n",
    "ingredient_df = get_data()\n",
    "preferences = initialize_children_data(get_child_data(), ingredient_df, seed=None, plot_graphs=False, split = 0.2)\n",
    "\n",
    "# # Example usage       # like             # dislike              # like                         # dislike                     # dislike\n",
    "ingredient_list = ['Sweet potatoes', 'Rice grain brown', 'Cow ox or bull fresh meat', 'Wheat bread and rolls brown or wholemeal', 'Aubergines']\n",
    "                # [like, dislike, like, like, dislike]\n",
    "feedback = get_feedback(preferences, ingredient_list, seed=None)\n",
    "\n",
    "# Extract preferences and update data\n",
    "changes, preferences, accuracy, incorrect_comments = extract_preferences_and_update_data(preferences, feedback, ingredient_list, plot_confusion_matrix=True)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "# Display the changes\n",
    "# for change in changes:\n",
    "#     print(f\"Child {change['child']} had {change['ingredient']} {change['change']}.\")\n",
    "\n",
    "display_incorrect_comments(incorrect_comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "# Load the sentiment analysis pipeline with a specific model\n",
    "sentiment_analyzer = pipeline('sentiment-analysis', model=\"finiteautomata/bertweet-base-sentiment-analysis\", device=device)\n",
    "\n",
    "def analyze_sentiment(comment):\n",
    "    result = sentiment_analyzer(comment)\n",
    "    label = result[0]['label']\n",
    "\n",
    "    if label == 'POS':\n",
    "        return 'likes'\n",
    "    elif label == 'NEG':\n",
    "        return 'dislikes'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import get_child_data, initialize_children_data, get_feedback\n",
    "from utils.process_data import get_data\n",
    "\n",
    "\n",
    "ingredient_df = get_data()\n",
    "preferences = initialize_children_data(get_child_data(), ingredient_df, seed=None, plot_graphs=False, split = 0.2)\n",
    "\n",
    "# # Example usage       # like             # dislike              # like                         # dislike                     # dislike\n",
    "ingredient_list = ['Sweet potatoes', 'Rice grain brown', 'Cow ox or bull fresh meat', 'Wheat bread and rolls brown or wholemeal', 'Aubergines']\n",
    "                # [like, dislike, like, like, dislike]\n",
    "feedback = get_feedback(preferences, ingredient_list, seed=None)\n",
    "\n",
    "# Extract preferences and update data\n",
    "changes, preferences, accuracy, incorrect_comments = extract_preferences_and_update_data(preferences, feedback, ingredient_list, plot_confusion_matrix=True)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "# Display the changes\n",
    "# for change in changes:\n",
    "#     print(f\"Child {change['child']} had {change['ingredient']} {change['change']}.\")\n",
    "\n",
    "display_incorrect_comments(incorrect_comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define utility matrix function\n",
    "def get_utility_matrix(children, ingredients, preferences):\n",
    "    utility_matrix = np.zeros((len(children), len(ingredients)))\n",
    "    for i, child in enumerate(children):\n",
    "        for j, ingredient in enumerate(ingredients):\n",
    "            if ingredient in preferences[child]['known'][\"likes\"]:\n",
    "                utility_matrix[i, j] = 1  # Likes are marked with 1\n",
    "            elif ingredient in preferences[child]['known'][\"neutral\"]:\n",
    "                utility_matrix[i, j] = 0  # Neutral is marked with 0\n",
    "            elif ingredient in preferences[child]['known'][\"dislikes\"]:\n",
    "                utility_matrix[i, j] = -1  # Dislikes are marked with -1\n",
    "    return utility_matrix\n",
    "\n",
    "# Define the function to create the known mask\n",
    "def create_known_mask(target_child, ingredients, preferences):\n",
    "    known_ingredients = (preferences[target_child]['known']['likes'] + \n",
    "                         preferences[target_child]['known']['neutral'] + \n",
    "                         preferences[target_child]['known']['dislikes'])\n",
    "    known_mask = np.isin(ingredients, known_ingredients)\n",
    "    return known_mask\n",
    "\n",
    "# Define the user-based prediction function\n",
    "def predict_preferences_user_based(target_child_index, user_similarity_matrix, utility_matrix, ingredients, preferences, clf):\n",
    "    target_child = 'child' + str(target_child_index + 1)\n",
    "    weighted_sum = np.dot(user_similarity_matrix[target_child_index], utility_matrix)\n",
    "    sum_of_weights = np.sum(user_similarity_matrix[target_child_index])\n",
    "    predicted_preferences = weighted_sum / sum_of_weights if sum_of_weights != 0 else np.zeros(len(ingredients))\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(predicted_preferences.reshape(-1, 1))\n",
    "    y = utility_matrix[target_child_index]\n",
    "    \n",
    "    \n",
    "    known_mask = create_known_mask(target_child, ingredients, preferences)\n",
    "    \n",
    "    if np.sum(known_mask) < 2:  # Ensure we have at least two classes for training\n",
    "        return np.full(len(ingredients), -1)\n",
    "    \n",
    "    clf.fit(X[known_mask], y[known_mask])\n",
    "    predicted_classes = clf.predict(X)\n",
    "    return predicted_classes\n",
    "\n",
    "# Define the item-based prediction function\n",
    "def predict_preferences_item_based(target_child_index, item_similarity_matrix, utility_matrix, ingredients, preferences, clf):\n",
    "    target_child = 'child' + str(target_child_index + 1)\n",
    "    # Get the preferences of the target child\n",
    "    child_preferences = utility_matrix[target_child_index]\n",
    "    \n",
    "    # Calculate the weighted sum of item similarities for each item\n",
    "    weighted_sum = np.dot(item_similarity_matrix, child_preferences)\n",
    "    \n",
    "    # Calculate the sum of weights for normalization\n",
    "    sum_of_weights = np.sum(item_similarity_matrix, axis=1)\n",
    "    \n",
    "    # Normalize the weighted sum to get predicted preferences\n",
    "    # Handle cases where sum_of_weights is zero\n",
    "    predicted_preferences = np.divide(weighted_sum, sum_of_weights, out=np.zeros_like(weighted_sum), where=sum_of_weights != 0)\n",
    "    \n",
    "    # Replace NaNs with 0\n",
    "    predicted_preferences = np.nan_to_num(predicted_preferences)\n",
    "    \n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(predicted_preferences.reshape(-1, 1))\n",
    "    y = utility_matrix[target_child_index]\n",
    "    \n",
    "    # Only use known preferences for training\n",
    "    known_mask = create_known_mask(target_child, ingredients, preferences)\n",
    "\n",
    "    if np.sum(known_mask) < 2:  # Ensure we have at least two classes for training\n",
    "        return np.full(len(ingredients), -1)\n",
    "    \n",
    "    clf.fit(X[known_mask], y[known_mask])\n",
    "    \n",
    "    # Predict the classes\n",
    "    predicted_classes = clf.predict(X)\n",
    "    return predicted_classes\n",
    "# Define the function to evaluate predictions\n",
    "def evaluate_predictions(children, ingredients, preferences, utility_matrix, similarity_matrix, predict_preferences_function, clf, plot_confusion_matrix=False):\n",
    "    class_map = {-1: 'dislikes', 0: 'neutral', 1: 'likes'}\n",
    "    label_mapping = {1: 0, 0: 1, -1: 2}  # Map class labels to integers for confusion matrix\n",
    "    total_correct_known = 0\n",
    "    total_correct_unknown = 0\n",
    "    total_incorrect = 0\n",
    "    total_known = 0\n",
    "    total_unknown = 0\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for target_child_index in range(len(children)):\n",
    "        child_key = 'child' + str(target_child_index + 1)\n",
    "        predicted_classes = predict_preferences_function(target_child_index, similarity_matrix, utility_matrix, ingredients, preferences, clf)\n",
    "        ingredient_ratings = {ingredient: rating for ingredient, rating in zip(ingredients, predicted_classes)}\n",
    "        \n",
    "        correct_known = 0\n",
    "        correct_unknown = 0\n",
    "        incorrect = 0\n",
    "        known = 0\n",
    "        unknown = 0\n",
    "\n",
    "        known_preferences = set(preferences[child_key]['known']['likes']) | set(preferences[child_key]['known']['dislikes']) | set(preferences[child_key]['known']['neutral'])\n",
    "        unknown_preferences = set(preferences[child_key]['unknown']['likes']) | set(preferences[child_key]['unknown']['dislikes']) | set(preferences[child_key]['unknown']['neutral'])\n",
    "        \n",
    "        print(f\"\\nPreferences for {child_key}:\")\n",
    "        for ingredient, rating in ingredient_ratings.items():\n",
    "            is_correct = False\n",
    "            true_label = None\n",
    "            if ingredient in known_preferences:\n",
    "                if ingredient in preferences[child_key]['known'][\"likes\"]:\n",
    "                    true_label = 1\n",
    "                elif ingredient in preferences[child_key]['known'][\"neutral\"]:\n",
    "                    true_label = 0\n",
    "                elif ingredient in preferences[child_key]['known'][\"dislikes\"]:\n",
    "                    true_label = -1\n",
    "            elif ingredient in unknown_preferences:\n",
    "                if ingredient in preferences[child_key]['unknown'][\"likes\"]:\n",
    "                    true_label = 1\n",
    "                elif ingredient in preferences[child_key]['unknown'][\"neutral\"]:\n",
    "                    true_label = 0\n",
    "                elif ingredient in preferences[child_key]['unknown'][\"dislikes\"]:\n",
    "                    true_label = -1\n",
    "\n",
    "            true_labels.append(true_label)\n",
    "            pred_labels.append(rating)\n",
    "\n",
    "            if rating in class_map:\n",
    "                if ingredient in preferences[child_key]['unknown'].get(class_map[rating], []):\n",
    "                    print(f\"{ingredient}: {rating}.  CORRECT, UNKNOWN\")\n",
    "                    correct_unknown += 1\n",
    "                    unknown += 1\n",
    "                    is_correct = True\n",
    "                elif ingredient in preferences[child_key]['known'].get(class_map[rating], []):\n",
    "                    print(f\"{ingredient}: {rating}.  CORRECT, KNOWN\")\n",
    "                    correct_known += 1\n",
    "                    known += 1\n",
    "                    is_correct = True\n",
    "            \n",
    "            if not is_correct:\n",
    "                print(f\"{ingredient}: {rating}.  INCORRECT\")\n",
    "                incorrect += 1\n",
    "                if ingredient in unknown_preferences:\n",
    "                    unknown += 1\n",
    "                elif ingredient in known_preferences:\n",
    "                    known += 1\n",
    "\n",
    "        total_predictions_child = correct_known + correct_unknown + incorrect\n",
    "        accuracy = (correct_known + correct_unknown) / total_predictions_child if total_predictions_child > 0 else 0\n",
    "        known_accuracy = (correct_known / known) if known > 0 else 0\n",
    "        unknown_accuracy = (correct_unknown / unknown) if unknown > 0 else 0\n",
    "        print(f\"\\nAccuracy Metrics for {child_key}:\")\n",
    "        print(f\"Correct (Known): {correct_known} / {known} ({known_accuracy * 100:.2f}%)\")\n",
    "        print(f\"Correct (Unknown): {correct_unknown} / {unknown} ({unknown_accuracy * 100:.2f}%)\")\n",
    "        print(f\"Incorrect: {incorrect}\")\n",
    "        print(f\"Total Predictions: {total_predictions_child}\")\n",
    "        print(f\"Overall Accuracy: {accuracy:.2f}\")\n",
    "        \n",
    "        total_correct_known += correct_known\n",
    "        total_correct_unknown += correct_unknown\n",
    "        total_incorrect += incorrect\n",
    "        total_known += known\n",
    "        total_unknown += unknown\n",
    "    \n",
    "    overall_total_predictions = total_correct_known + total_correct_unknown + total_incorrect\n",
    "    overall_accuracy = (total_correct_known + total_correct_unknown) / overall_total_predictions if overall_total_predictions > 0 else 0\n",
    "    overall_known_accuracy = (total_correct_known / total_known) if total_known > 0 else 0\n",
    "    overall_unknown_accuracy = (total_correct_unknown / total_unknown) if total_unknown > 0 else 0\n",
    "    print(f\"\\nOverall Accuracy Metrics:\")\n",
    "    print(f\"Correct (Known): {total_correct_known} / {total_known} ({overall_known_accuracy * 100:.2f}%)\")\n",
    "    print(f\"Correct (Unknown): {total_correct_unknown} / {total_unknown} ({overall_unknown_accuracy * 100:.2f}%)\")\n",
    "    print(f\"Incorrect: {total_incorrect}\")\n",
    "    print(f\"Total Predictions: {overall_total_predictions}\")\n",
    "    print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "\n",
    "    # Plot confusion matrix if flag is set\n",
    "    if plot_confusion_matrix and overall_total_predictions > 0:\n",
    "        cm = confusion_matrix([label_mapping[label] for label in true_labels], \n",
    "                              [label_mapping[label] for label in pred_labels], \n",
    "                              labels=[0, 1, 2])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['likes', 'neutral', 'dislikes'])\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Classifier Models with tuned parameters\n",
    "def get_classifier(classifier_name = 'RandomForest'):\n",
    "    if classifier_name == 'LogisticRegression':\n",
    "        solver = 'liblinear'\n",
    "        class_weight = None\n",
    "        C = 0.4022301244444916\n",
    "        clf = LogisticRegression(solver=solver, class_weight=class_weight, C=C, max_iter=10000)\n",
    "    elif classifier_name == 'RandomForest':\n",
    "        n_estimators = 58\n",
    "        max_depth = 11  \n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    elif classifier_name == 'SVC':\n",
    "        C = 3.5244469291048874\n",
    "        kernel = 'rbf'\n",
    "        clf = SVC(C=C, kernel=kernel, probability=True)\n",
    "    elif classifier_name == 'SGDClassifier':\n",
    "        alpha = 0.0018872854402943308\n",
    "        max_iter = 3928  \n",
    "        clf = SGDClassifier(alpha=alpha, max_iter=max_iter)\n",
    "    return clf\n",
    "\n",
    "\n",
    "# Best hyperparameters:  {'solver': 'lbfgs', 'class_weight': None, 'C': 6.2232422446177145}\n",
    "# Best accuracy:  0.6775398303643858\n",
    "\n",
    "# {'C': 3.5244469291048874, 'kernel': 'rbf'} SVC\n",
    "\n",
    "# Best hyperparameters:  {'n_estimators': 58, 'max_depth': 11} RandomForest\n",
    "# Best accuracy:  0.7418735389051784\n",
    "\n",
    "# Best hyperparameters:  {'alpha': 0.0018872854402943308, 'max_iter': 3928}\n",
    "# Best accuracy:  0.6574125625058961  (SGDClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the item similarity matrix represents the cosine similarity between two ingredients. The value ranges from -1 to 1, where 1 indicates maximum similarity, 0 indicates no similarity, and -1 indicates maximum dissimilarity.\n",
    "\n",
    "Higher similarity values between ingredients suggest that children who like (or dislike) one ingredient tend to have similar preferences for the other ingredient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted preferences array represents the estimated ratings a child would give to each ingredient, based on their current preferences and the similarities between ingredients.\n",
    "\n",
    "Higher predicted preference values indicate a higher likelihood that the child will like the ingredient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept: In user-based collaborative filtering, the idea is to find users who are similar to the target user based on their ratings and preferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have the functions get_child_data, get_data, and initialize_children_data\n",
    "children = list(get_child_data().keys())  # Get the list of children\n",
    "ingredient_df = get_data(\"data.csv\")  # Get the ingredient data\n",
    "ingredients = ingredient_df['Category7'].to_list()  # Convert ingredients to a list\n",
    "preferences = initialize_children_data(get_child_data(), ingredient_df, seed=None, plot_graphs=False, split=0.5)  # Initialize children data with preferences\n",
    "\n",
    "# Get the utility matrix based on updated preferences\n",
    "utility_matrix = get_utility_matrix(children, ingredients, preferences)\n",
    "\n",
    "# Calculate user similarity matrix\n",
    "user_similarity_matrix = cosine_similarity(utility_matrix)\n",
    "\n",
    "# Calculate item similarity matrix (using transposed utility matrix)\n",
    "item_similarity_matrix = cosine_similarity(utility_matrix.T)\n",
    "\n",
    "clf = get_classifier('SGDClassifier')\n",
    "# Evaluate item-based predictions\n",
    "print(\"\\nUser-Based Predictions:\")\n",
    "evaluate_predictions(children, ingredients, preferences, utility_matrix, user_similarity_matrix, predict_preferences_user_based, clf, plot_confusion_matrix=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept: In item-based collaborative filtering, the idea is to find items that are similar to the ones the target user has liked. Recommendations are then made based on the similarity between items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate item-based predictions\n",
    "print(\"\\nItem-Based Predictions:\")\n",
    "evaluate_predictions(children, ingredients, preferences, utility_matrix, item_similarity_matrix, predict_preferences_item_based, clf, plot_confusion_matrix=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Item-based collaborative filtering with added features tends to be less sparse and more effective than user-based methods with added features because item features are stable, consistent, and richly described. These characteristics lead to a densely populated item similarity matrix, which can aggregate preferences more effectively and provide better coverage for recommendations. Additionally, item-based methods are more scalable and can handle sparse user interactions more gracefully, making them a preferred choice in many recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Define the function to evaluate predictions\n",
    "def evaluate_predictions(children, ingredients, preferences, utility_matrix, similarity_matrix, predict_preferences_function, clf):\n",
    "    total_correct_known = 0\n",
    "    total_correct_unknown = 0\n",
    "    total_incorrect = 0\n",
    "    total_known = 0\n",
    "    total_unknown = 0\n",
    "    \n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    for target_child_index in range(len(children)):\n",
    "        child_key = \"child\" + str(target_child_index + 1)\n",
    "        predicted_classes = predict_preferences_function(target_child_index, similarity_matrix, utility_matrix, ingredients, preferences, clf)\n",
    "        ingredient_ratings = {ingredient: rating for ingredient, rating in zip(ingredients, predicted_classes)}\n",
    "        \n",
    "        correct_known = 0\n",
    "        correct_unknown = 0\n",
    "        incorrect = 0\n",
    "        known = 0\n",
    "        unknown = 0\n",
    "\n",
    "        known_preferences = set(preferences[child_key]['known']['likes']) | set(preferences[child_key]['known']['dislikes']) | set(preferences[child_key]['known']['neutral'])\n",
    "        unknown_preferences = set(preferences[child_key]['unknown']['likes']) | set(preferences[child_key]['unknown']['dislikes']) | set(preferences[child_key]['unknown']['neutral'])\n",
    "        \n",
    "        for ingredient, rating in ingredient_ratings.items():\n",
    "            is_correct = False\n",
    "            true_label = None\n",
    "            if ingredient in known_preferences:\n",
    "                if ingredient in preferences[child_key]['known'][\"likes\"]:\n",
    "                    true_label = 1\n",
    "                elif ingredient in preferences[child_key]['known'][\"neutral\"]:\n",
    "                    true_label = 0\n",
    "                elif ingredient in preferences[child_key]['known'][\"dislikes\"]:\n",
    "                    true_label = -1\n",
    "            elif ingredient in unknown_preferences:\n",
    "                if ingredient in preferences[child_key]['unknown'][\"likes\"]:\n",
    "                    true_label = 1\n",
    "                elif ingredient in preferences[child_key]['unknown'][\"neutral\"]:\n",
    "                    true_label = 0\n",
    "                elif ingredient in preferences[child_key]['unknown'][\"dislikes\"]:\n",
    "                    true_label = -1\n",
    "\n",
    "            true_labels.append(true_label)\n",
    "            pred_labels.append(rating)\n",
    "\n",
    "            if ingredient in preferences[child_key]['unknown'].get('likes', []) and rating == 1:\n",
    "                correct_unknown += 1\n",
    "                unknown += 1\n",
    "                is_correct = True\n",
    "            elif ingredient in preferences[child_key]['unknown'].get('dislikes', []) and rating == -1:\n",
    "                correct_unknown += 1\n",
    "                unknown += 1\n",
    "                is_correct = True\n",
    "            elif ingredient in preferences[child_key]['unknown'].get('neutral', []) and rating == 0:\n",
    "                correct_unknown += 1\n",
    "                unknown += 1\n",
    "                is_correct = True\n",
    "            elif ingredient in preferences[child_key]['known'].get('likes', []) and rating == 1:\n",
    "                correct_known += 1\n",
    "                known += 1\n",
    "                is_correct = True\n",
    "            elif ingredient in preferences[child_key]['known'].get('dislikes', []) and rating == -1:\n",
    "                correct_known += 1\n",
    "                known += 1\n",
    "                is_correct = True\n",
    "            elif ingredient in preferences[child_key]['known'].get('neutral', []) and rating == 0:\n",
    "                correct_known += 1\n",
    "                known += 1\n",
    "                is_correct = True\n",
    "            \n",
    "            if not is_correct:\n",
    "                incorrect += 1\n",
    "                if ingredient in unknown_preferences:\n",
    "                    unknown += 1\n",
    "                elif ingredient in known_preferences:\n",
    "                    known += 1\n",
    "\n",
    "        total_predictions_child = correct_known + correct_unknown + incorrect\n",
    "        accuracy = (correct_known + correct_unknown) / total_predictions_child if total_predictions_child > 0 else 0\n",
    "        known_accuracy = (correct_known / known) if known > 0 else 0\n",
    "        unknown_accuracy = (correct_unknown / unknown) if unknown > 0 else 0\n",
    "        \n",
    "        total_correct_known += correct_known\n",
    "        total_correct_unknown += correct_unknown\n",
    "        total_incorrect += incorrect\n",
    "        total_known += known\n",
    "        total_unknown += unknown\n",
    "    \n",
    "    overall_total_predictions = total_correct_known + total_correct_unknown + total_incorrect\n",
    "    overall_accuracy = (total_correct_known + total_correct_unknown) / overall_total_predictions if overall_total_predictions > 0 else 0\n",
    "    overall_known_accuracy = (total_correct_known / total_known) if total_known > 0 else 0\n",
    "    overall_unknown_accuracy = (total_correct_unknown / total_unknown) if total_unknown > 0 else 0\n",
    "    \n",
    "    # Compute the F1 score\n",
    "    f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
    "    \n",
    "    return f1\n",
    "    \n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    preferences = initialize_children_data(get_child_data(), ingredient_df, seed=None, plot_graphs=False, split=0.5)  # Initialize children data with preferences\n",
    "    \n",
    "    # Define hyperparameters to tune\n",
    "    classifier_names = ['LogisticRegression', 'RandomForest', 'SVC', 'SGDClassifier']\n",
    "    classifier_name = classifier_names[3]\n",
    "    # Choose between item-based or user-based recommendation\n",
    "    recommendation_methods = ['item_based', 'user_based']\n",
    "    recommendation_method = recommendation_methods[1]\n",
    "    \n",
    "    # Define classifier based on chosen name\n",
    "    if classifier_name == 'LogisticRegression':\n",
    "        solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "        class_weight = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "        C = trial.suggest_float('C', 0.1, 10.0)\n",
    "        clf = LogisticRegression(solver=solver, class_weight=class_weight, C=C, max_iter=10000)\n",
    "    elif classifier_name == 'RandomForest':\n",
    "        n_estimators = trial.suggest_int('n_estimators', 10, 200)\n",
    "        max_depth = trial.suggest_int('max_depth', 2, 32, log=True)\n",
    "        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    elif classifier_name == 'SVC':\n",
    "        C = trial.suggest_float('C', 0.1, 10.0)\n",
    "        kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
    "        clf = SVC(C=C, kernel=kernel, probability=True)\n",
    "    else:  # SGDClassifier\n",
    "        alpha = trial.suggest_float('alpha', 0.00001, 0.1)\n",
    "        max_iter = trial.suggest_int('max_iter', 1000, 10000)\n",
    "        clf = SGDClassifier(alpha=alpha, max_iter=max_iter)\n",
    "    \n",
    "    # Get the utility matrix based on updated preferences\n",
    "    utility_matrix = get_utility_matrix(children, ingredients, preferences)\n",
    "\n",
    "    # Compute the appropriate similarity matrix\n",
    "    if recommendation_method == 'item_based':\n",
    "        item_similarity_matrix = cosine_similarity(utility_matrix.T)\n",
    "        similarity_matrix = item_similarity_matrix\n",
    "        predict_preferences_function = predict_preferences_item_based\n",
    "    else:  # user_based\n",
    "        user_similarity_matrix = cosine_similarity(utility_matrix)\n",
    "        similarity_matrix = user_similarity_matrix\n",
    "        predict_preferences_function = predict_preferences_user_based\n",
    "    \n",
    "    # Evaluate the model using the provided function\n",
    "    f1 = evaluate_predictions(\n",
    "        children, ingredients, preferences, utility_matrix, similarity_matrix, predict_preferences_function, clf\n",
    "    )\n",
    "    \n",
    "    return f1\n",
    "\n",
    "from models.preferences.data_utils import get_child_data, initialize_children_data\n",
    "from utils.process_data import get_data\n",
    "\n",
    "children = list(get_child_data().keys())  # Get the list of children\n",
    "ingredient_df = get_data(\"data.csv\")  # Get the ingredient data\n",
    "ingredients = ingredient_df['Category7'].to_list()  # Convert ingredients to a list\n",
    "\n",
    "\n",
    "# Create Optuna study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "\n",
    "print(\"Best hyperparameters: \", study.best_params)\n",
    "print(\"Best accuracy: \", study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a classifier to predict if a child will like an ingredient based on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, make_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def get_data_preprocessor():\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"age\", OneHotEncoder(), [\"age\"]),\n",
    "            (\"gender\", OneHotEncoder(), [\"gender\"]),\n",
    "            (\"health_consideration\", OneHotEncoder(), [\"health_consideration\"]),\n",
    "            (\"favorite_cuisine\", OneHotEncoder(), [\"favorite_cuisine\"]),\n",
    "            (\"type\", OneHotEncoder(), [\"type\"]),\n",
    "            (\"colour\", OneHotEncoder(), [\"colour\"]),\n",
    "            (\"taste\", OneHotEncoder(), [\"taste\"]),\n",
    "            (\"texture\", OneHotEncoder(), [\"texture\"]),\n",
    "            (\"healthy\", OneHotEncoder(), [\"healthy\"]),\n",
    "        ],\n",
    "    )\n",
    "    return preprocessor\n",
    "# Function to prepare data for the machine learning model\n",
    "def prepare_ml_data(preferences, ingredient_df, child_data, apply_SMOTE=False, seed=42):\n",
    "    # Create a DataFrame from child_data\n",
    "    child_df = pd.DataFrame.from_dict(child_data, orient='index').reset_index().rename(columns={'index': 'child'})\n",
    "    \n",
    "    # Create a DataFrame from preferences\n",
    "    preferences_df = pd.DataFrame(preferences).T.reset_index().rename(columns={'index': 'child'})\n",
    "    \n",
    "    # Melt preferences DataFrame\n",
    "    likes_df = preferences_df.explode('likes')[['child', 'likes']].rename(columns={'likes': 'ingredient'})\n",
    "    likes_df['preference'] = 5\n",
    "    \n",
    "    neutral_df = preferences_df.explode('neutral')[['child', 'neutral']].rename(columns={'neutral': 'ingredient'})\n",
    "    neutral_df['preference'] = 3\n",
    "    \n",
    "    dislikes_df = preferences_df.explode('dislikes')[['child', 'dislikes']].rename(columns={'dislikes': 'ingredient'})\n",
    "    dislikes_df['preference'] = 1\n",
    "    \n",
    "    # Concatenate all preference DataFrames\n",
    "    preferences_long_df = pd.concat([likes_df, neutral_df, dislikes_df])\n",
    "    \n",
    "    # Merge child data with preferences\n",
    "    combined_df = pd.merge(child_df, preferences_long_df, on='child')\n",
    "    \n",
    "    # Merge the combined DataFrame with the ingredient DataFrame\n",
    "    df = pd.merge(combined_df, ingredient_df[['Category7', 'Category1', 'Colour', 'Texture', 'Taste', 'Healthy']], left_on='ingredient', right_on='Category7')\n",
    "\n",
    "    # Drop the redundant 'Category7' column after the merge\n",
    "    df.drop(columns=['Category7'], inplace=True)\n",
    "\n",
    "    # Rename columns to match the desired output\n",
    "    df.rename(columns={\n",
    "        'ingredient': 'ingredient',\n",
    "        'Category1': 'type',\n",
    "        'Colour': 'colour',\n",
    "        'Texture': 'texture',\n",
    "        'Taste': 'taste',\n",
    "        'Healthy': 'healthy'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Select and reorder the final columns\n",
    "    df = df[['age', 'gender', 'health_consideration', 'favorite_cuisine', 'ingredient', 'type', 'colour', 'texture', 'taste', 'healthy', 'preference']]\n",
    "    \n",
    "    # Encode the target variable\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"preference\"] = label_encoder.fit_transform(df[\"preference\"])\n",
    "\n",
    "    # Define the preprocessor for numerical and categorical features\n",
    "    preprocessor = get_data_preprocessor()\n",
    "\n",
    "    # Drop the target column before fitting the preprocessor, this will occur in column transformer but done to make it resilient to changes.\n",
    "    X = df.drop(columns=['preference'])\n",
    "    y = df[\"preference\"].values\n",
    "\n",
    "    # Fit the preprocessor\n",
    "    preprocessor = preprocessor.fit(X)\n",
    "\n",
    "    # Apply the transformations and prepare the dataset\n",
    "    X = preprocessor.transform(X)\n",
    "    \n",
    "    if apply_SMOTE:\n",
    "        # Convert sparse matrix to dense format\n",
    "        X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
    "        # Apply SMOTE to balance the classes\n",
    "        smote = SMOTE(random_state=seed)\n",
    "        X_res, y_res = smote.fit_resample(X_dense, y)\n",
    "        \n",
    "        # Convert back to DataFrame\n",
    "        X_res_df = pd.DataFrame(X_res, columns=preprocessor.get_feature_names_out())\n",
    "        y_res_df = pd.DataFrame(y_res, columns=['preference'])\n",
    "        \n",
    "        # Concatenate X and y\n",
    "        df_res = pd.concat([X_res_df, y_res_df], axis=1)\n",
    "        \n",
    "        # Update df, X, and y\n",
    "        df = df_res\n",
    "        X = X_res\n",
    "        y = y_res\n",
    "\n",
    "    return X, y, df, label_encoder, preprocessor\n",
    "\n",
    "def get_models():\n",
    "    # Initialize the models\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=200),\n",
    "        \"Support Vector Machine\": SVC(),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
    "        \"Random Forest\": RandomForestClassifier(),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "        \"AdaBoost\": AdaBoostClassifier(algorithm='SAMME'),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=1),\n",
    "        \"Decision Tree\": DecisionTreeClassifier()\n",
    "    }\n",
    "    return models\n",
    "\n",
    "def evaluate_models(X, y, n_splits=5):\n",
    "\n",
    "    # Define scorers with zero_division=0 to handle undefined metric cases\n",
    "    scorers = {\n",
    "        'precision_macro': make_scorer(precision_score, average='macro', zero_division=0),\n",
    "        'recall_macro': make_scorer(recall_score, average='macro', zero_division=0),\n",
    "        'f1_macro': make_scorer(f1_score, average='macro', zero_division=0),\n",
    "        'accuracy': make_scorer(accuracy_score)\n",
    "    }\n",
    "\n",
    "    # Evaluate models using cross-validation\n",
    "    results = []\n",
    "    accuracy_scores = {}\n",
    "    for name, model in get_models().items():\n",
    "        for scorer_name, scorer in scorers.items():\n",
    "            score = cross_val_score(model, X, y, cv=StratifiedKFold(n_splits=n_splits), scoring=scorer)\n",
    "            results.append({\n",
    "                \"Model\": name,\n",
    "                \"Metric\": scorer_name,\n",
    "                \"Score\": score.mean()\n",
    "            })\n",
    "            if scorer_name == 'accuracy':\n",
    "                accuracy_scores[name] = score.mean()\n",
    "\n",
    "    # Convert results to DataFrame for easy comparison\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df, accuracy_scores\n",
    "\n",
    "\n",
    "def get_ranked_models(results_df):\n",
    "    # Rank models for each metric\n",
    "    ranked_results = results_df.copy()\n",
    "    ranked_results['Rank'] = ranked_results.groupby('Metric')['Score'].rank(ascending=False, method='min')\n",
    "\n",
    "    # Convert results to DataFrame for easy comparison\n",
    "    results_df_sorted = ranked_results.sort_values(by=['Metric', 'Rank'])\n",
    "\n",
    "    print(results_df_sorted)\n",
    "    \n",
    "def get_confusion_matrix(X, y, accuracy_scores, models, label_encoder):\n",
    "    # Identify the best model based on accuracy\n",
    "    best_model_name = max(accuracy_scores, key=accuracy_scores.get)\n",
    "    best_model = models[best_model_name]\n",
    "\n",
    "    # Fit the best model on the entire dataset and predict\n",
    "    best_model.fit(X, y)\n",
    "    y_pred = best_model.predict(X)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix for {best_model_name}')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import initialize_children_data, get_child_data\n",
    "from utils.process_data import get_data\n",
    "\n",
    "ingredients_df = get_data(\"data.csv\")\n",
    "preferences = initialize_children_data(child_data=get_child_data(), ingredient_df=ingredients_df, seed=None, plot_graphs=False, split=0.5)\n",
    "child_data = get_child_data()\n",
    "models = get_models()\n",
    "\n",
    "for child in preferences:\n",
    "    ml_preferences[child] = {}\n",
    "    ml_preferences[child]['likes'] = preferences[child]['known']['likes'] + preferences[child]['unknown']['likes']\n",
    "    ml_preferences[child]['neutral'] = preferences[child]['known']['neutral'] + preferences[child]['unknown']['neutral']\n",
    "    ml_preferences[child]['dislikes'] = preferences[child]['known']['dislikes'] + preferences[child]['unknown']['dislikes']\n",
    "\n",
    "# # Prepare the data\n",
    "X, y, df, label_encoder, preprocessor = prepare_ml_data(ml_preferences, ingredients_df, child_data)\n",
    "\n",
    "results_df, accuracy_scores = evaluate_models(X, y)\n",
    "\n",
    "get_ranked_models(results_df)\n",
    "\n",
    "get_confusion_matrix(X, y, accuracy_scores, models, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Measures the accuracy of the positive predictions. High precision means that fewer false positives are present.\n",
    "\n",
    "Recall: Measures the ability to capture all positive instances. High recall means that fewer false negatives are present.\n",
    "\n",
    "F1 Score: The harmonic mean of precision and recall. It provides a balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "Popular data augmentation technique used to address class imbalance in datasets.\n",
    "\n",
    "Identify Minority Class: First, SMOTE identifies the samples belonging to the minority class in the dataset.\n",
    "\n",
    "Select a Sample: For each sample in the minority class, SMOTE selects one or more of its nearest neighbors (usually based on Euclidean distance) within the same class.\n",
    "\n",
    "Generate Synthetic Samples: New synthetic samples are generated along the line segments joining the selected sample and its nearest neighbors. The position of the synthetic sample is determined by selecting a random point along the line segment. This ensures that the new samples are not just copies of existing ones but are rather slightly varied versions.\n",
    "\n",
    "Repeat the Process: This process is repeated until the desired level of balance between the classes is achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import initialize_children_data, get_child_data\n",
    "from utils.process_data import get_data\n",
    "\n",
    "ingredients_df = get_data(\"data.csv\")\n",
    "preferences = initialize_children_data(child_data=get_child_data(), ingredient_df=ingredients_df, seed=None, plot_graphs=False, split=0.5)\n",
    "child_data = get_child_data()\n",
    "models = get_models()\n",
    "\n",
    "ml_preferences = {}\n",
    "\n",
    "for child in preferences:\n",
    "    ml_preferences[child] = {}\n",
    "    ml_preferences[child]['likes'] = preferences[child]['known']['likes'] + preferences[child]['unknown']['likes']\n",
    "    ml_preferences[child]['neutral'] = preferences[child]['known']['neutral'] + preferences[child]['unknown']['neutral']\n",
    "    ml_preferences[child]['dislikes'] = preferences[child]['known']['dislikes'] + preferences[child]['unknown']['dislikes']\n",
    "    \n",
    "# # Prepare the data\n",
    "X, y, df, label_encoder, preprocessor = prepare_ml_data(ml_preferences, ingredients_df, child_data)\n",
    "\n",
    "# Convert sparse matrix to dense format if necessary\n",
    "X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_dense, y)\n",
    "\n",
    "# Convert the transformed data back to a DataFrame for visualization\n",
    "transformed_df = pd.DataFrame(X_resampled)\n",
    "\n",
    "# Can increase n_splits as more data generated with smote\n",
    "results_df, accuracy_scores = evaluate_models(X_resampled, y_resampled, n_splits=5)\n",
    "\n",
    "get_ranked_models(results_df)\n",
    "\n",
    "get_confusion_matrix(X_resampled, y_resampled, accuracy_scores, models, label_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results, it is evident that the machine learning method currently outperforms the collaborative filtering approach. However, it's important to note that with significantly larger datasets or improvements in data quality, the collaborative filtering method could potentially become more effective and surpass the performance of the machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negotiation of preference\n",
    "Now that we have estimated predictions for each ingredient based on various features, we can utilise this information to create an optimized meal plan that aims to satisfy every child. Additionally, we can incorporate other relevant features and stakeholder inputs into the process, feeding this enriched data into a reinforcement learning (RL) program to further refine and enhance the meal planning strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get trained model using all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Prepare the data\n",
    "X, y, label_encoder, preprocessor = prepare_ml_data(preferences, ingredients_data, child_data)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import get_supplier_availability\n",
    "from utils.process_data import get_data\n",
    "ingredient_df = get_data()\n",
    "get_supplier_availability(ingredient_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import get_supplier_availability\n",
    "from models.preferences.prediction import predict_preference_using_model\n",
    "\n",
    "def collect_weighted_votes(preferences, ingredient_type, rf_model, preprocessor, child_data, ingredient_df, weight_function):\n",
    "    supplier_availability = get_supplier_availability(ingredient_df)\n",
    "    \n",
    "    available_ingredients = {ingredient: 0 for ingredient, type in zip(ingredient_df['Category7'], ingredient_df['Category1']) if type == ingredient_type and supplier_availability.get(ingredient, False)}\n",
    "    unavailable_ingredients = [ingredient for ingredient, available in supplier_availability.items() if not available and ingredient in ingredient_df['Category7'].values and ingredient_df[ingredient_df['Category7'] == ingredient]['Category1'].values[0] == ingredient_type]\n",
    "    preference_to_rating_mapping = {0: 0, 1: 3, 2: 5}\n",
    "    for child, pref in preferences.items():\n",
    "        # Prepare child features for prediction\n",
    "        child_features = {\n",
    "            \"age\": child_data[child][\"age\"],\n",
    "            \"gender\": child_data[child][\"gender\"],\n",
    "            \"health_consideration\": child_data[child][\"health_consideration\"],\n",
    "            \"favorite_cuisine\": child_data[child][\"favorite_cuisine\"]\n",
    "        }\n",
    "        \n",
    "        # Calculate weights based on preferences and stability\n",
    "        weights = weight_function(child, pref)\n",
    "        \n",
    "        likes = set(pref['known'][\"likes\"])\n",
    "        neutrals = set(pref['known'][\"neutral\"])\n",
    "        dislikes = set(pref['known'][\"dislikes\"])\n",
    "        \n",
    "        # Update available ingredients' scores based on preferences and weights\n",
    "        for ingredient in available_ingredients.keys():\n",
    "            if ingredient in likes:\n",
    "                available_ingredients[ingredient] += 5 * weights['likes']\n",
    "            elif ingredient in neutrals:\n",
    "                available_ingredients[ingredient] += 3 * weights['neutral']\n",
    "            elif ingredient in dislikes:\n",
    "                available_ingredients[ingredient] += 0 * weights['dislikes']\n",
    "            else: # In the unknown list and have to predict\n",
    "                # Predict preference for ingredients not explicitly liked or disliked\n",
    "                ingredient_details = ingredient_df[ingredient_df['Category7'] == ingredient].iloc[0]\n",
    "                ingredient_features = {\n",
    "                    \"ingredient\": ingredient,\n",
    "                    \"type\": ingredient_details[\"Category1\"],\n",
    "                    \"texture\": ingredient_details[\"Texture\"],\n",
    "                    \"colour\": ingredient_details[\"Colour\"],\n",
    "                    \"taste\": ingredient_details[\"Taste\"],\n",
    "                    \"healthy\": ingredient_details[\"Healthy\"]\n",
    "                }\n",
    "                predicted_preference = predict_preference_using_model(child_features, ingredient_features, child, rf_model, preprocessor)\n",
    "                \n",
    "                if predicted_preference == 3:\n",
    "                    pass\n",
    "                \n",
    "                available_ingredients[ingredient] += preference_to_rating_mapping[predicted_preference] * weights['dislikes']\n",
    "            \n",
    "    return available_ingredients, unavailable_ingredients\n",
    "\n",
    "def negotiate_ingredients_simple(preferences, rf_model, preprocessor, child_data, ingredient_df, weight_function):\n",
    "    ingredient_types = set(ingredient_df['Category1'])\n",
    "    negotiated_ingredients = {}\n",
    "    unavailable_ingredients = {}\n",
    "\n",
    "    for ingredient_type in ingredient_types:\n",
    "        votes, unavailable = collect_weighted_votes(preferences, ingredient_type, rf_model, preprocessor, child_data, ingredient_df, weight_function)\n",
    "        sorted_ingredients = sorted(votes, key=votes.get, reverse=True)\n",
    "        negotiated_ingredients[ingredient_type] = sorted_ingredients\n",
    "        if unavailable:\n",
    "            unavailable_ingredients[ingredient_type] = unavailable\n",
    "    \n",
    "    return negotiated_ingredients, unavailable_ingredients\n",
    "\n",
    "def calculate_child_weight_simple(child, preferences):\n",
    "    return {\n",
    "        'likes': 1,\n",
    "        'neutral': 1,\n",
    "        'dislikes': 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_preprocessor():\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"age\", OneHotEncoder(), [\"age\"]),\n",
    "            (\"gender\", OneHotEncoder(), [\"gender\"]),\n",
    "            (\"health_consideration\", OneHotEncoder(), [\"health_consideration\"]),\n",
    "            (\"favorite_cuisine\", OneHotEncoder(), [\"favorite_cuisine\"]),\n",
    "            (\"type\", OneHotEncoder(), [\"type\"]),\n",
    "            (\"colour\", OneHotEncoder(), [\"colour\"]),\n",
    "            (\"taste\", OneHotEncoder(), [\"taste\"]),\n",
    "            (\"texture\", OneHotEncoder(), [\"texture\"]),\n",
    "            (\"healthy\", OneHotEncoder(), [\"healthy\"]),\n",
    "        ],\n",
    "    )\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import prince\n",
    "import plotly.express as px\n",
    "import random\n",
    "from utils.process_data import get_data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, Tuple\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    " # Function to prepare data for the machine learning model\n",
    "def prepare_ml_data(preferences, ingredient_df, child_data, apply_SMOTE=False, seed=42):\n",
    "    # Create a DataFrame from child_data\n",
    "    child_df = pd.DataFrame.from_dict(child_data, orient='index').reset_index().rename(columns={'index': 'child'})\n",
    "    \n",
    "    # Create a DataFrame from preferences\n",
    "    preferences_df = pd.DataFrame(preferences).T.reset_index().rename(columns={'index': 'child'})\n",
    "    \n",
    "    # Melt preferences DataFrame\n",
    "    likes_df = preferences_df.explode('likes')[['child', 'likes']].rename(columns={'likes': 'ingredient'})\n",
    "    likes_df['preference'] = 5\n",
    "    \n",
    "    neutral_df = preferences_df.explode('neutral')[['child', 'neutral']].rename(columns={'neutral': 'ingredient'})\n",
    "    neutral_df['preference'] = 3\n",
    "    \n",
    "    dislikes_df = preferences_df.explode('dislikes')[['child', 'dislikes']].rename(columns={'dislikes': 'ingredient'})\n",
    "    dislikes_df['preference'] = 1\n",
    "    \n",
    "    unknown_df = preferences_df.explode('unknown')[['child', 'unknown']].rename(columns={'unknown': 'ingredient'})\n",
    "    unknown_df['preference'] = np.nan\n",
    "    \n",
    "    # Concatenate all preference DataFrames\n",
    "    preferences_long_df = pd.concat([likes_df, neutral_df, dislikes_df, unknown_df])\n",
    "    \n",
    "    # Merge child data with preferences\n",
    "    combined_df = pd.merge(child_df, preferences_long_df, on='child')\n",
    "    \n",
    "    # Merge the combined DataFrame with the ingredient DataFrame\n",
    "    df = pd.merge(combined_df, ingredient_df[['Category7', 'Category1', 'Colour', 'Texture', 'Taste', 'Healthy']], left_on='ingredient', right_on='Category7')\n",
    "\n",
    "    # Drop the redundant 'Category7' column after the merge\n",
    "    df.drop(columns=['Category7'], inplace=True)\n",
    "\n",
    "    # Rename columns to match the desired output\n",
    "    df.rename(columns={\n",
    "        'ingredient': 'ingredient',\n",
    "        'Category1': 'type',\n",
    "        'Colour': 'colour',\n",
    "        'Texture': 'texture',\n",
    "        'Taste': 'taste',\n",
    "        'Healthy': 'healthy'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Select and reorder the final columns\n",
    "    df = df[['age', 'gender', 'health_consideration', 'favorite_cuisine', 'ingredient', 'type', 'colour', 'texture', 'taste', 'healthy', 'preference']]\n",
    "    \n",
    "    # Encode the target variable\n",
    "    label_encoder = LabelEncoder()\n",
    "    df[\"preference\"] = label_encoder.fit_transform(df[\"preference\"].astype(str))\n",
    "    \n",
    "    print(df[\"preference\"].tolist())\n",
    "\n",
    "    # Define the preprocessor for numerical and categorical features\n",
    "    preprocessor = get_data_preprocessor()\n",
    "\n",
    "    # Drop the target column before fitting the preprocessor\n",
    "    X = df.drop(columns=['preference'])\n",
    "    y = df[\"preference\"].values\n",
    "\n",
    "    # Fit the preprocessor\n",
    "    preprocessor.fit(X)\n",
    "\n",
    "    # Apply the transformations and prepare the dataset\n",
    "    X_transformed = preprocessor.transform(X)\n",
    "\n",
    "    # Drop rows with NaN preferences in the original DataFrame\n",
    "    known_df = df.dropna(subset=['preference'])\n",
    "\n",
    "    # Extract the indices of known preferences\n",
    "    known_indices = known_df.index\n",
    "\n",
    "    # Filter X_transformed and y to only include known preferences\n",
    "    X = X_transformed[known_indices]\n",
    "    y = y[known_indices]\n",
    "    \n",
    "    if apply_SMOTE:\n",
    "        # Convert sparse matrix to dense format\n",
    "        X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
    "        # Apply SMOTE to balance the classes\n",
    "        smote = SMOTE(random_state=seed)\n",
    "        X_res, y_res = smote.fit_resample(X_dense, y)\n",
    "        \n",
    "        # Convert back to DataFrame\n",
    "        X_res_df = pd.DataFrame(X_res, columns=preprocessor.get_feature_names_out())\n",
    "        y_res_df = pd.DataFrame(y_res, columns=['preference'])\n",
    "        \n",
    "        # Concatenate X and y\n",
    "        df_res = pd.concat([X_res_df, y_res_df], axis=1)\n",
    "        \n",
    "        # Update df, X, and y\n",
    "        df = df_res\n",
    "        X = X_res\n",
    "        y = y_res\n",
    "\n",
    "    return X, y, df, label_encoder, preprocessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Workflow\n",
    "\n",
    "+ Retrieve Data\n",
    "+ Train predictor model\n",
    "+ Negotiate Order\n",
    "+ Retrieve Feedback\n",
    "+ Update Preferences with Feedback\n",
    "+ Update Predictor Model\n",
    "\n",
    "+ Example Meal Plan: [onions, red pepper, egg plant, chicken, cauliflower, potatoes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import initialize_children_data, get_child_data\n",
    "from utils.process_data import get_data\n",
    "\n",
    "ingredient_df = get_data(\"data.csv\")\n",
    "preferences = initialize_children_data(child_data=get_child_data(), ingredient_df=ingredient_df, seed=None, plot_graphs=False, split=0.8)\n",
    "child_data = get_child_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Predictor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import prepare_ml_data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ml_preferences = {}\n",
    "\n",
    "for child in preferences:\n",
    "    ml_preferences[child] = {}\n",
    "    ml_preferences[child]['likes'] = preferences[child]['known']['likes']\n",
    "    ml_preferences[child]['neutral'] = preferences[child]['known']['neutral']\n",
    "    ml_preferences[child]['dislikes'] = preferences[child]['known']['dislikes']\n",
    "    \n",
    "    # Determine unknown features\n",
    "    known_ingredients = set(preferences[child]['known']['likes'] + preferences[child]['known']['neutral'] + preferences[child]['known']['dislikes'])\n",
    "    all_ingredients = set(ingredient_df['Category1'])\n",
    "    unknown_ingredients = all_ingredients - known_ingredients\n",
    "    \n",
    "    ml_preferences[child]['unknown'] = list(unknown_ingredients)\n",
    "\n",
    "\n",
    "# # Prepare the data\n",
    "X, y, df, label_encoder, preprocessor = prepare_ml_data(ml_preferences, ingredient_df, get_child_data())\n",
    "\n",
    "# Convert sparse matrix to dense format if necessary\n",
    "X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_dense, y)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negotiate order of preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negotiated_ingredients, old_unavailable = negotiate_ingredients_simple(preferences, rf_model, preprocessor, child_data, ingredient_df, calculate_child_weight_simple)\n",
    "\n",
    "print(\"Negotiated order of preferred ingredients by type:\")\n",
    "for ingredient_type, ingredients in negotiated_ingredients.items():\n",
    "    print(f\"{ingredient_type.capitalize()}: {', '.join(ingredients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import get_feedback, initialize_children_data, get_child_data\n",
    "from utils.process_data import get_data\n",
    "import random\n",
    "\n",
    "ingredient_df = get_data(\"data.csv\")\n",
    "menu_plan = random.sample(list(ingredient_df['Category7']), 5)\n",
    "\n",
    "preferences = initialize_children_data(get_child_data(), ingredient_df)\n",
    "\n",
    "print(menu_plan)\n",
    "\n",
    "feedback = get_feedback(preferences, menu_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Preferences with Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_preferences_and_update_data(preferences, feedback, menu_plan, plot_confusion_matrix=False):\n",
    "    changes = []\n",
    "    incorrect_comments = []\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    # Mapping for confusion matrix\n",
    "    label_mapping = {'likes': 5, 'neutral': 3, 'dislikes': 0}\n",
    "\n",
    "    # Check if GPU is available and set device accordingly\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    # Load the sentiment analysis pipeline with a specific model\n",
    "    sentiment_analyzer = pipeline('sentiment-analysis', model=\"finiteautomata/bertweet-base-sentiment-analysis\", device=device)\n",
    "    \n",
    "    # Iterate over each child's feedback\n",
    "    for child, fb in feedback.items():\n",
    "        # Split comments into sentences based on punctuation\n",
    "        comments = re.split(r'[,.!?]', fb[\"comment\"].lower())\n",
    "        correct_action = fb[\"correct_action\"]\n",
    "        \n",
    "        # Analyze each comment's sentiment\n",
    "        for sentence in comments:\n",
    "            if sentence.strip():  # Check if the sentence is not empty\n",
    "                comment = sentence.strip()\n",
    "                pred_label = analyze_sentiment(comment, sentiment_analyzer)\n",
    "                \n",
    "                # Check for mentions of each ingredient in the sentence\n",
    "                for ingredient in menu_plan:\n",
    "                    if ingredient.lower() in sentence:\n",
    "                        change = {\"child\": child, \"ingredient\": ingredient, \"change\": \"\"}\n",
    "                        \n",
    "                        # Determine the appropriate category based on polarity\n",
    "                        if pred_label == 'likes':  \n",
    "                            if ingredient not in preferences[child]['known'][\"likes\"]:\n",
    "                                preferences[child]['known'][\"likes\"].append(ingredient)\n",
    "                                change[\"change\"] = \"added to likes\"\n",
    "                        elif pred_label == 'dislikes':\n",
    "                            if ingredient not in preferences[child]['known'][\"dislikes\"]:\n",
    "                                preferences[child]['known'][\"dislikes\"].append(ingredient)\n",
    "                                change[\"change\"] = \"added to dislikes\"\n",
    "                        else:\n",
    "                            pred_label = 'neutral'\n",
    "                            if ingredient not in preferences[child]['known'][\"neutral\"]:\n",
    "                                preferences[child]['known'][\"neutral\"].append(ingredient)\n",
    "                                change[\"change\"] = \"added to neutral\"\n",
    "                        \n",
    "                        # Remove ingredient from other lists\n",
    "                        if change[\"change\"]:\n",
    "                            if change[\"change\"] != \"added to likes\" and ingredient in preferences[child]['known'][\"likes\"]:\n",
    "                                preferences[child]['known'][\"likes\"].remove(ingredient)\n",
    "                                change[\"change\"] += \", removed from likes\"\n",
    "                            if change[\"change\"] != \"added to dislikes\" and ingredient in preferences[child]['known'][\"dislikes\"]:\n",
    "                                preferences[child]['known']['dislikes'].remove(ingredient)\n",
    "                                change[\"change\"] += \", removed from dislikes\"\n",
    "                            if change[\"change\"] != \"added to neutral\" and ingredient in preferences[child]['known'][\"neutral\"]:\n",
    "                                preferences[child]['known'][\"neutral\"].remove(ingredient)\n",
    "                                change[\"change\"] += \", removed from neutral\"\n",
    "                            \n",
    "                            changes.append(change)\n",
    "                        \n",
    "                        true_labels.append(correct_action[ingredient])\n",
    "                        pred_labels.append(pred_label)\n",
    "                        \n",
    "                        # Check if the prediction was incorrect\n",
    "                        if pred_label != correct_action[ingredient]:\n",
    "                            incorrect_comments.append({\n",
    "                                \"child\": child,\n",
    "                                \"comment\": sentence,\n",
    "                                \"predicted\": pred_label,\n",
    "                                \"actual\": correct_action[ingredient]\n",
    "                            })\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct_actions = sum(1 for true, pred in zip(true_labels, pred_labels) if true == pred)\n",
    "    total_actions = len(true_labels)\n",
    "    accuracy = correct_actions / total_actions if total_actions > 0 else 0\n",
    "\n",
    "    # Plot confusion matrix if flag is set\n",
    "    if plot_confusion_matrix and total_actions > 0:\n",
    "        cm = confusion_matrix([label_mapping[label] for label in true_labels], \n",
    "                              [label_mapping[label] for label in pred_labels], \n",
    "                              labels=[0, 1, 2])\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['likes', 'neutral', 'dislikes'])\n",
    "        disp.plot(cmap=plt.cm.Blues)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    return changes, preferences, accuracy, incorrect_comments\n",
    "\n",
    "\n",
    "# Function to display the changes made to children's preferences\n",
    "def display_changes(changes):\n",
    "    for change in changes:\n",
    "        print(\"Action Taken:\\n\")\n",
    "        print(f\"Child {change['child']} had {change['ingredient']} {change['change']}.\")\n",
    "        \n",
    "# Function to display incorrect comments and reasons\n",
    "def display_incorrect_comments(incorrect_comments):\n",
    "    for comment in incorrect_comments:\n",
    "        print(f\"Child {comment['child']} commented: '{comment['comment']}'\")\n",
    "        print(f\"Predicted: {comment['predicted']}, Actual: {comment['actual']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Check if GPU is available and set device accordingly\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "# Load the sentiment analysis pipeline with a specific model\n",
    "sentiment_analyzer = pipeline('sentiment-analysis', model=\"finiteautomata/bertweet-base-sentiment-analysis\", device=device)\n",
    "\n",
    "def analyze_sentiment(comment, sentiment_analyzer):\n",
    "    result = sentiment_analyzer(comment)\n",
    "    label = result[0]['label']\n",
    "\n",
    "    if label == 'POS':\n",
    "        return 'likes'\n",
    "    elif label == 'NEG':\n",
    "        return 'dislikes'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Update children_data and get the list of changes\n",
    "changes, updated_preferences, accuracy, incorrect_comments = extract_preferences_and_update_data(preferences, feedback, menu_plan)\n",
    "\n",
    "# Function to display the changes made to children's preferences\n",
    "def display_changes(changes):\n",
    "    for change in changes:\n",
    "        print(\"Action Taken:\\n\")\n",
    "        print(f\"Child {change['child']} had {change['ingredient']} {change['change']}.\")\n",
    "        \n",
    "# Function to display incorrect comments and reasons\n",
    "def display_incorrect_comments(incorrect_comments):\n",
    "    for comment in incorrect_comments:\n",
    "        print(f\"Child {comment['child']} commented: '{comment['comment']}'\")\n",
    "        print(f\"Predicted: {comment['predicted']}, Actual: {comment['actual']}\\n\")\n",
    "\n",
    "# # Display the changes\n",
    "display_changes(changes)\n",
    "\n",
    "display_incorrect_comments(incorrect_comments)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_preferences)\n",
    "print(preferences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain predictor model with updated preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.preferences.data_utils import get_child_data, prepare_ml_data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ml_preferences = {}\n",
    "\n",
    "for child in updated_preferences:\n",
    "    ml_preferences[child] = {}\n",
    "    ml_preferences[child]['likes'] = updated_preferences[child]['known']['likes']\n",
    "    ml_preferences[child]['neutral'] = updated_preferences[child]['known']['neutral']\n",
    "    ml_preferences[child]['dislikes'] = updated_preferences[child]['known']['dislikes']\n",
    "    \n",
    "    # Determine unknown features\n",
    "    known_ingredients = set(updated_preferences[child]['known']['likes'] + updated_preferences[child]['known']['neutral'] + updated_preferences[child]['known']['dislikes'])\n",
    "    all_ingredients = set(ingredient_df['Category1'])\n",
    "    unknown_ingredients = all_ingredients - known_ingredients\n",
    "    \n",
    "    ml_preferences[child]['unknown'] = list(unknown_ingredients)\n",
    "\n",
    "\n",
    "# # Prepare the data\n",
    "X, y, df, label_encoder, preprocessor = prepare_ml_data(ml_preferences, ingredient_df, get_child_data())\n",
    "\n",
    "# Convert sparse matrix to dense format if necessary\n",
    "X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_dense, y)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New supplier availability list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renegotiate order of preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renegotiated_ingredients, new_unavailable = negotiate_ingredients_simple(updated_preferences, rf_model, preprocessor, get_child_data(), ingredient_df, calculate_child_weight_simple)\n",
    "\n",
    "print(\"Negotiated order of preferred ingredients by type:\")\n",
    "for ingredient_type, ingredients in negotiated_ingredients.items():\n",
    "    print(f\"{ingredient_type.capitalize()}: {', '.join(ingredients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare two negotiated lists to see what has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ordered_list(ingredients_list):\n",
    "    return {ingredient: index + 1 for index, ingredient in enumerate(ingredients_list)}\n",
    "\n",
    "def compare_negotiated_ingredients(old_ingredients, new_ingredients, old_unavailable, new_unavailable):\n",
    "    changes = {}\n",
    "\n",
    "    all_ingredient_types = set(old_ingredients.keys()).union(new_ingredients.keys()).union(old_unavailable.keys()).union(new_unavailable.keys())\n",
    "\n",
    "    for ingredient_type in all_ingredient_types:\n",
    "        old_list = old_ingredients.get(ingredient_type, [])\n",
    "        new_list = new_ingredients.get(ingredient_type, [])\n",
    "        old_unavail_list = old_unavailable.get(ingredient_type, [])\n",
    "        new_unavail_list = new_unavailable.get(ingredient_type, [])\n",
    "\n",
    "        old_order = generate_ordered_list(old_list)\n",
    "        new_order = generate_ordered_list(new_list)\n",
    "\n",
    "        order_changes = []\n",
    "        for ingredient in set(old_order.keys()).union(new_order.keys()).union(old_unavail_list).union(new_unavail_list):\n",
    "            old_pos = old_order.get(ingredient, 'Unavailable')\n",
    "            new_pos = new_order.get(ingredient, \"Error\")\n",
    "            \n",
    "            if ingredient in old_unavail_list:\n",
    "                old_pos = 'Unavailable'\n",
    "            if ingredient in new_unavail_list:\n",
    "                new_pos = 'Unavailable'\n",
    "                \n",
    "            if old_pos != new_pos:\n",
    "                order_changes.append((ingredient, old_pos, new_pos))\n",
    "\n",
    "        if order_changes:\n",
    "            changes[ingredient_type] = order_changes\n",
    "\n",
    "    return changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = compare_negotiated_ingredients(negotiated_ingredients, renegotiated_ingredients, old_unavailable, new_unavailable)\n",
    "\n",
    "# Display the changes in a readable format\n",
    "for ingredient_type, order_changes in changes.items():\n",
    "    print(f\"Changes in {ingredient_type}:\")\n",
    "    for ingredient, old_pos, new_pos in order_changes:\n",
    "        print(f\"{ingredient}: Pos: {old_pos} -> Pos: {new_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Principles\n",
    "**Equity Principle**: We integrated the equity principle by considering the impact of a child's vote through the number of preferences.\n",
    "\n",
    "The initial method for weighting votes relied on the total number of preferences (likes, neutrals, and dislikes) each child expressed. This approach can unintentionally give more influence to children with a higher number of preferences. To ensure a fairer distribution of votes, we should adjust the weights of the votes more thoughtfully, considering both the type of preferences and the number of preferences each child has.\n",
    "\n",
    "To achieve this, votes will be normalized so that each child's dislike, neutral, and like votes have a similar impact. For example, if one child dislikes 20 ingredients while another child dislikes only 2, the child with fewer dislikes would have a disproportionately small dislike impact if the votes were not adjusted with a weighting factor. Therefore, it is prudent to make the impact of one child’s 20 dislikes more comparable to the impact of another child’s 2 dislikes, ensuring each child's preferences are equitably represented.\n",
    "\n",
    "**Need Principle**: \n",
    "+ Firstly, This principle is addressed by categorizing ingredients by type, ensuring that an ingredient from each group is chosen. \n",
    "+ Secondly, in the top 10% of the list no child will have all their disliked ingredients contained within. Otherwise, their basic needs will not be met, as they will continually receive items they dislike. This prevents any one child not meeting nutritional targets.\n",
    "\n",
    "**Meritocracy Principle**\n",
    "\n",
    "+ To incorporate the principle of meritocracy, we must define actions that contribute to our collective goal: providing healthier, cheaper, and improved nutrition in school meals.\n",
    "+ The children help achieve this by reducing food waste and improving their preferences.\n",
    "\n",
    "Therefore, to give merit to good actions:\n",
    "\n",
    "1. **Proportional Voting Weight**:\n",
    "   - The weight of a child's vote will be proportional to their like/dislike ratio. For example, if a child dislikes 10 ingredients but likes only 5, their vote will account for 50% less compared to a child who likes and dislikes an equal number of ingredients.\n",
    "\n",
    "2. **Feedback Participation**:\n",
    "   - Children who actively participate in giving feedback on previous meals will have increased voting power. Conversely, those who do not provide feedback will have reduced voting power for their preferences.\n",
    "\n",
    "3. **Merit Points for Good Behavior**:\n",
    "   - Children can earn merit points for positive behaviors such as reducing food waste. More merit points will translate to a more powerful vote.\n",
    "\n",
    "**Transparency and Communication**\n",
    "\n",
    "+ The system must be transparent. Ensure that the criteria for earning merit points and the conversion of these points to voting power are clearly communicated and understood by all participants.\n",
    "\n",
    "+ By implementing these measures, we aim to create a fair and motivating environment that encourages children to contribute positively towards our collective goal of improving school meals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_data = get_child_data()\n",
    "ingredients_data = get_ingredient_data()\n",
    "preferences = get_preference_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_child_weight(child, preferences):\n",
    "    \n",
    "    # Normalize likes, neutrals, and dislikes so each child has equal contribution\n",
    "    total_likes = len(preferences[\"likes\"])\n",
    "    total_neutrals = len(preferences[\"neutral\"])\n",
    "    total_dislikes = len(preferences[\"dislikes\"])\n",
    "    \n",
    "    # Make vote proportional to like/dislike ratio\n",
    "    like_dislike_ratio = total_likes / total_dislikes\n",
    "    \n",
    "    child_merit_weight = 1  # Placeholder for child-specific merit\n",
    "    \n",
    "    if str(child) in get_feedback().keys():\n",
    "        feedback_provided_weight = 1\n",
    "    else:\n",
    "        feedback_provided_weight = 0.9\n",
    "    \n",
    "    # Ensure each category contributes equally\n",
    "    normalized_likes = 1 / max(1, total_likes)\n",
    "    normalized_neutrals = 1 / max(1, total_neutrals)\n",
    "    normalized_dislikes = 1 / max(1, total_dislikes)\n",
    "    \n",
    "    return {\n",
    "        'likes': normalized_likes * like_dislike_ratio * child_merit_weight * feedback_provided_weight,\n",
    "        'neutral': normalized_neutrals * like_dislike_ratio * child_merit_weight * feedback_provided_weight,\n",
    "        'dislikes': normalized_dislikes * like_dislike_ratio * child_merit_weight * feedback_provided_weight\n",
    "    }\n",
    "\n",
    "def collect_weighted_votes(preferences, ingredient_type, rf_model, preprocessor, child_data, ingredients_data):\n",
    "    supplier_availability = get_supplier_availability()\n",
    "    \n",
    "    available_ingredients = {ingredient: 0 for ingredient, details in ingredients_data.items() if details['type'] == ingredient_type and supplier_availability.get(ingredient, False)}\n",
    "    unavailable_ingredients = [ingredient for ingredient, available in supplier_availability.items() if not available and ingredient in ingredients_data and ingredients_data[ingredient]['type'] == ingredient_type]\n",
    "    \n",
    "    for child, pref in preferences.items():\n",
    "        \n",
    "        # Prepare child features for prediction\n",
    "        child_features = {\n",
    "            \"age\": child_data[child][\"age\"],\n",
    "            \"gender\": 1 if child_data[child][\"gender\"] == \"M\" else 0,\n",
    "            \"health_consideration\": child_data[child][\"health_consideration\"],\n",
    "            \"favorite_cuisine\": child_data[child][\"favorite_cuisine\"]\n",
    "        }\n",
    "        \n",
    "        # Calculate weights based on preferences and stability\n",
    "        weights = calculate_child_weight(child, pref)\n",
    "        \n",
    "        likes = set(pref[\"likes\"])\n",
    "        neutrals = set(pref[\"neutral\"])\n",
    "        dislikes = set(pref[\"dislikes\"])\n",
    "        \n",
    "        # Update available ingredients' scores based on preferences and weights\n",
    "        for ingredient in available_ingredients.keys():\n",
    "            if ingredient in likes:\n",
    "                available_ingredients[ingredient] += 5 * weights['likes']\n",
    "            elif ingredient in neutrals:\n",
    "                available_ingredients[ingredient] += 3 * weights['neutral']\n",
    "            elif ingredient not in dislikes:\n",
    "                # Predict preference for ingredients not explicitly liked or disliked\n",
    "                ingredient_details = ingredients_data[ingredient]\n",
    "                ingredient_features = {\n",
    "                    \"ingredient\": ingredient,\n",
    "                    \"type\": ingredient_details[\"type\"],\n",
    "                    \"color\": ingredient_details[\"color\"],\n",
    "                    \"taste\": ingredient_details[\"taste\"]\n",
    "                }\n",
    "                predicted_preference = predict_preference(child_features, ingredient_features, rf_model, preprocessor)\n",
    "                available_ingredients[ingredient] += predicted_preference * weights['dislikes']\n",
    "    \n",
    "    return available_ingredients, unavailable_ingredients\n",
    "\n",
    "def negotiate_ingredients(preferences, rf_model, preprocessor, child_data, ingredients_data):\n",
    "    ingredient_types = set(details['type'] for details in ingredients_data.values())\n",
    "    negotiated_ingredients = {}\n",
    "    unavailable_ingredients = {}\n",
    "\n",
    "    for ingredient_type in ingredient_types:\n",
    "        votes, unavailable = collect_weighted_votes(preferences, ingredient_type, rf_model, preprocessor, child_data, ingredients_data)\n",
    "        \n",
    "        # Sort ingredients based on votes\n",
    "        sorted_ingredients = sorted(votes, key=votes.get, reverse=True)\n",
    "        top_10_percent = sorted_ingredients[:max(1, len(sorted_ingredients) // 10)]\n",
    "        \n",
    "        # Check top 10% and ensure no child has all their dislikes in this section\n",
    "        for child, pref in preferences.items():\n",
    "            dislikes_in_top_10 = set(pref['dislikes']).intersection(top_10_percent)\n",
    "            if len(dislikes_in_top_10) == len(top_10_percent):\n",
    "                # If all top 10% are disliked by one child, reassign scores to balance\n",
    "                for dislike in dislikes_in_top_10:\n",
    "                    votes[dislike] -= 1  # Penalize disliked items slightly\n",
    "                    sorted_ingredients = sorted(votes, key=votes.get, reverse=True)\n",
    "                    top_10_percent = sorted_ingredients[:max(1, len(sorted_ingredients) // 10)]\n",
    "        \n",
    "        negotiated_ingredients[ingredient_type] = sorted_ingredients\n",
    "        \n",
    "        # Track unavailable ingredients\n",
    "        if unavailable:\n",
    "            unavailable_ingredients[ingredient_type] = unavailable\n",
    "    \n",
    "    return negotiated_ingredients, unavailable_ingredients\n",
    "\n",
    "\n",
    "\n",
    "negotiated_ingredients_resher, unavailable_ingredients_resher = negotiate_ingredients(preferences, rf_model, preprocessor, child_data, ingredients_data)\n",
    "\n",
    "print(\"Negotiated Ingredients:\", negotiated_ingredients)\n",
    "print(\"Unavailable Ingredients:\", unavailable_ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = compare_negotiated_ingredients(negotiated_ingredients_after_feedback, negotiated_ingredients_resher, new_unavailable, unavailable_ingredients_resher)\n",
    "\n",
    "# Display the changes in a readable format\n",
    "for ingredient_type, order_changes in changes.items():\n",
    "    print(f\"Changes in {ingredient_type}:\")\n",
    "    for ingredient, old_pos, new_pos in order_changes:\n",
    "        print(f\"{ingredient}: Pos: {old_pos} -> Pos: {new_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Function to plot 3D MCA components interactively\n",
    "def plot_3d_mca_interactive(X, y):\n",
    "    # Ensure we only take the first three components\n",
    "    if X.shape[1] < 3:\n",
    "        raise ValueError(\"Input data must have at least 3 principal components for a 3D plot.\")\n",
    "    \n",
    "    # Create a DataFrame with the first three MCA components and the labels\n",
    "    df = X.iloc[:, :3]\n",
    "    df.columns = ['MC1', 'MC2', 'MC3'] \n",
    "    df['Preference'] = y\n",
    "    \n",
    "    # Create an interactive 3D scatter plot\n",
    "    fig = px.scatter_3d(df, x='MC1', y='MC2', z='MC3', color='Preference', \n",
    "                        title='3D MCA Interactive Plot', labels={'Preference': 'Preference'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot scree plot for MCA\n",
    "def plot_scree_mca(preprocessor, n_components=10):\n",
    "    # Extract the MCA step from the pipeline\n",
    "    # Extract the explained inertia from the MCA step\n",
    "    mca_step = pipeline.named_steps['mca']\n",
    "    explained_inertia = mca_step.explained_inertia_\n",
    "    # Plot the explained variance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, n_components + 1), explained_inertia, marker='o', linestyle='--')\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('MCA Component')\n",
    "    plt.ylabel('Explained Inertia Ratio')\n",
    "    plt.xticks(range(1, n_components + 1))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_df = get_ingredient_data()\n",
    "preferences = get_preference_data()\n",
    "child_data = get_child_data()\n",
    "X, y, label_encoder, preprocessor = prepare_ml_data(preferences, ingredient_df, child_data)\n",
    "\n",
    "# Convert sparse matrix to dense format if necessary\n",
    "X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X_dense, y)\n",
    "\n",
    "print(X_resampled.shape)\n",
    "# from sklearn.manifold import TSNE\n",
    "# tsne = TSNE(n_components=2, perplexity=30, n_iter=300)\n",
    "# tsne_components = tsne.fit_transform(one_hot_encoded_df)\n",
    "\n",
    "\n",
    "# plot_3d_mca(X, y)\n",
    "# plot_2d_mca(X, y)\n",
    "# plot_3d_mca_interactive(X, y)\n",
    "# plot_scree_mca(preprocessor, n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "# # Assuming X is your feature DataFrame and y is your target Series\n",
    "tsne = TSNE(n_components=2, perplexity=5, max_iter=5000)\n",
    "tsne_components = tsne.fit_transform(X_resampled)\n",
    "\n",
    "# Creating a DataFrame with t-SNE components and the target variable\n",
    "tsne_df = pd.DataFrame(data=tsne_components, columns=['TSNE 1', 'TSNE 2'])\n",
    "tsne_df['Target'] = y_resampled\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(tsne_df['TSNE 1'], tsne_df['TSNE 2'], c=tsne_df['Target'])\n",
    "plt.xlabel('TSNE 1')\n",
    "plt.ylabel('TSNE 2')\n",
    "plt.title('t-SNE of One-Hot Encoded Data')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming X is your feature DataFrame and y is your target Series\n",
    "tsne = TSNE(n_components=2, perplexity=100, max_iter=5000)\n",
    "tsne_components = tsne.fit_transform(X_resampled)\n",
    "\n",
    "# Creating a DataFrame with t-SNE components and the target variable\n",
    "tsne_df = pd.DataFrame(data=tsne_components, columns=['TSNE 1', 'TSNE 2'])\n",
    "tsne_df['Target'] = y_resampled\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(tsne_df['TSNE 1'], tsne_df['TSNE 2'], c=tsne_df['Target'])\n",
    "plt.xlabel('TSNE 1')\n",
    "plt.ylabel('TSNE 2')\n",
    "plt.title('t-SNE of One-Hot Encoded Data')\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using project data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process_data import get_data\n",
    "from models.preferences.data_utils import prepare_ml_data, get_child_data, initialize_children_data\n",
    "from models.preferences.data_utils import plot_2d_mca, plot_3d_mca, plot_3d_mca_interactive, plot_scree_mca\n",
    "from imblearn.over_sampling import SMOTE\n",
    "child_data = get_child_data()\n",
    "ingredient_df = get_data(\"data.csv\")\n",
    "\n",
    "preferences = initialize_children_data(child_data, ingredient_df)\n",
    "\n",
    "# print(preferences)\n",
    "\n",
    "X, y, df, label_encoder, preprocessor = prepare_ml_data(preferences, ingredient_df, child_data)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# # Convert sparse matrix to dense format if necessary\n",
    "X_dense = X.toarray() if hasattr(X, 'toarray') else X\n",
    "\n",
    "# print(X_dense.shape)\n",
    "# # Apply SMOTE\n",
    "# smote = SMOTE(random_state=42)\n",
    "\n",
    "# X_resampled, y_resampled = smote.fit_resample(X_dense, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import prince\n",
    "\n",
    "# Assuming df is your DataFrame with one-hot encoded categorical features\n",
    "# Example data loading\n",
    "# df = pd.read_csv('your_one_hot_encoded_data.csv')\n",
    "\n",
    "# Apply MCA\n",
    "mca = prince.MCA(n_components=2, n_iter=3, copy=True, check_input=True, engine='sklearn', random_state=42)\n",
    "mca = mca.fit(df)\n",
    "\n",
    "# Transform the data\n",
    "df_mca = mca.transform(df)\n",
    "\n",
    "# Print the explained variance\n",
    "print(f\"Explained Variance: {mca.explained_inertia_}\")\n",
    "\n",
    "# Plot the results\n",
    "ax = mca.plot_coordinates(df, ax=None, figsize=(10, 8), show_row_points=True, show_column_points=True,\n",
    "                          show_row_labels=False, show_column_labels=True)\n",
    "ax.set_title('MCA of One-Hot Encoded Data')\n",
    "ax.set_xlabel('MCA 1')\n",
    "ax.set_ylabel('MCA 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process_data import get_data\n",
    "from models.preferences.data_utils import prepare_ml_data, get_child_data, initialize_children_data\n",
    "from models.preferences.data_utils import plot_2d_mca, plot_3d_mca, plot_3d_mca_interactive, plot_scree_mca\n",
    "from imblearn.over_sampling import SMOTE\n",
    "child_data = get_child_data()\n",
    "ingredient_df = get_data(\"data.csv\")\n",
    "preferences = initialize_children_data(child_data, ingredient_df, seed=None)\n",
    "\n",
    "\n",
    "X, y, df, label_encoder, preprocessor = prepare_ml_data(preferences, ingredient_df, child_data)\n",
    "\n",
    "df.head()\n",
    "\n",
    "import prince\n",
    "\n",
    "mca = prince.MCA(\n",
    "    n_components=3,\n",
    "    n_iter=3,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine='sklearn',\n",
    "    random_state=42\n",
    ")\n",
    "mca = mca.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import prince\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Separate the features and class labels\n",
    "features = df.drop(columns=['preference'])\n",
    "class_labels = df['preference']\n",
    "\n",
    "\n",
    "# Apply MCA\n",
    "mca = prince.MCA(n_components=2, n_iter=30, copy=True, check_input=True, engine='sklearn', random_state=42)\n",
    "mca = mca.fit(features)\n",
    "\n",
    "# Transform the data\n",
    "df_mca = mca.transform(features)\n",
    "df_mca['class_label'] = class_labels.values\n",
    "\n",
    "# Get distinct colors for each class label\n",
    "unique_labels = class_labels.unique()\n",
    "palette = sns.color_palette(\"hsv\", len(unique_labels))\n",
    "color_dict = {label: palette[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Assign colors to each point based on the class label\n",
    "colors = [color_dict[label] for label in df_mca['class_label']]\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot of MCA results, color-coded by class labels\n",
    "scatter = ax.scatter(df_mca[0], df_mca[1], c=colors, alpha=0.6)\n",
    "\n",
    "# Add a legend\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color_dict[label], markersize=10, label=label) for label in unique_labels]\n",
    "ax.legend(title='Class Label', handles=handles)\n",
    "\n",
    "# Plot settings\n",
    "ax.set_title('MCA of One-Hot Encoded Data')\n",
    "ax.set_xlabel('MCA 1')\n",
    "ax.set_ylabel('MCA 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.plot(\n",
    "    df,\n",
    "    x_component=0,\n",
    "    y_component=1,\n",
    "    show_column_markers=True,\n",
    "    show_row_markers=True,\n",
    "    show_column_labels=False,\n",
    "    show_row_labels=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.column_contributions_.head().style.format('{:.010%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the negotiated list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negotiated_order = {'Group A veg': [('Carrots', 150), ('Peas', 150), ('Pepper', 150), ('Swedes', 150), ('Sweet corn', 150), ('Tomatoes', 150), ('Chili peppers', 134), ('Courgettes', 126), ('Leeks', 126), ('Asparagus', 124), ('Cucumber', 118), ('Aubergines', 114), ('Avocados', 114), ('Brussels sprouts', 106), ('Onions', 100), ('Spinaches', 82), ('Broccoli', 80), ('Garlic', 80), ('Spring onions', 80), ('Cauliflowers', 78), ('White cabbage', 78), ('Beetroots', 72), ('Parsnip roots', 68), ('Lettuces (generic)', 66), ('Savoy cabbages', 66), ('Curly kales', 64), ('Radishes', 64), ('Common bean sprouts', 62), ('Common mushrooms', 62), ('Jerusalem artichokes', 62), ('Turnips', 60), ('Red cabbage', 58), ('Runner beans (with pods)', 58), ('Celeries', 54)], \n",
    "                    'Group A fruit': [('Apples', 150), ('Cherries and similar-', 150), ('Common banana', 150), ('Mango', 150), ('Nectarines', 150), ('Oranges sweet', 150), ('Papayas', 150), ('Pears', 150), ('Pineapples', 150), ('Plums', 150), ('Raspberries', 150), ('Strawberries', 150), ('Table grapes', 150), ('Watermelons', 150), ('Blueberries', 112), ('Rhubarbs', 98), ('Limes', 74), ('Grapefruits', 66), ('Passionfruits', 62)], \n",
    "                    'Group BC': [('Kidney bean', 150), ('Coconuts', 144), ('Trouts', 118), ('Salmons', 114), ('Tuna', 114), ('Shrimps and prawns', 112), ('Fish fingers breaded', 110), ('Ham pork', 110), ('Anchovies', 106), ('Pig fresh meat', 106), ('Cow ox or bull fresh meat', 104), ('Turkey fresh meat', 104), ('Deer red fresh meat', 98), ('Chicken fresh meat', 96), ('Duck fresh meat', 96), ('Lamb fresh meat', 96), ('Breakfast-type sausage', 84), ('Frankfurter sausage', 84), ('Bacon', 82), ('Coalfish', 82), ('Mackerel', 78), ('Sea bass', 78), ('Sunflower seeds', 78), ('Hakes', 76), ('Peanuts', 76), ('Almonds', 74), ('Cashew nuts', 72), ('Cod', 72), ('Edible crab', 72), ('Hazelnuts', 72), ('Brazil nuts', 70), ('Haddock', 70), ('Herrings', 70), ('Chickpeas (dry)', 68), ('Lentils (dry)', 68), ('Eggs', 64), ('Pumpkin seeds', 52), ('Pistachios', 48)], 'Group D': [('Sweet potatoes', 150), ('Pasta plain (not stuffed) uncooked', 106), ('Noodles', 104), ('Pasta wholemeal', 100), ('Couscous', 94), ('New potatoes', 80), ('Buckwheat', 70), ('Potatoes', 60), ('Rice grain', 60), ('Rice grain long-grain', 56)], \n",
    "                    'Group E': [('Traditional margarine', 112), ('Yoghurt cow milk flavoured', 110), ('Butter', 106), ('Cheese cheddar', 106), ('Cow milk whole', 106), ('Parmesan', 104), ('Creme fraiche cheese', 102), ('Cream plain', 92), ('Mascarpone', 90), ('Cow milk skimmed (low fat)', 68), ('Cow milk semi skimmed (half fat)', 62), ('Sour cream', 58), ('Mozzarella', 54), ('Yoghurt cow milk plain', 54)], \n",
    "                    'Bread': [('Wheat bread and rolls white (refined flour)', 114), ('Wheat bread and rolls brown or wholemeal', 54)], \n",
    "                    'Confectionary': [('White chocolate', 116), ('White sugar', 110), ('Honey', 100), ('Bitter chocolate', 94)], \n",
    "                    'Misc': [('Basil', 106), ('Rosemary', 106), ('Oregano', 104), ('Parsley', 104), ('Corianders', 100), ('Rape seed oil edible', 94), ('Olive oil', 92), ('Sunflower seed oil edible', 90), ('Wheat wholemeal flour', 60), ('Wheat flour white', 52)]}\n",
    "\n",
    "\n",
    "unavailable = {'Kiwi fruits (green red yellow)', 'Palm oil/fat', 'Chocolate coated confectionery', 'Rice grain brown'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process_data import get_data\n",
    "\n",
    "ingredient_df = get_data(\"data.csv\")\n",
    "\n",
    "def convert_unavailable_to_index(unavailable_ingredients, ingredient_df):\n",
    "    # Get the indexes of rows where 'Category7' is in the list of unavailable ingredients\n",
    "    indexes = ingredient_df.index[ingredient_df['Category7'].isin(unavailable_ingredients)].tolist()\n",
    "    return indexes\n",
    "\n",
    "unavailable_indexes = convert_unavailable_to_index(unavailable, ingredient_df)\n",
    "\n",
    "print(unavailable)\n",
    "print(unavailable_indexes)\n",
    "\n",
    "ingredient_df['Category7'].iloc[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_ingredients = len(ingredient_df['Category7'].tolist())\n",
    "extra_action = 2  # First 2 for actions [do nothing, increase], rest for ingredients\n",
    "\n",
    "# Initialize action mask with ones\n",
    "action_mask = np.ones(extra_action + n_ingredients, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in unavailable_indexes:\n",
    "    action_mask[idx + extra_action] = 0\n",
    "    \n",
    "print(action_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def create_preference_score_function(ranked_ingredients):\n",
    "    \"\"\"\n",
    "    Creates a score function for picking ingredients based on ranked ingredients.\n",
    "\n",
    "    Parameters:\n",
    "    ranked_ingredients (dict): Dictionary with ingredient groups as keys and lists of tuples (ingredient, score) as values.\n",
    "\n",
    "    Returns:\n",
    "    function: A function that takes an ingredient as input and returns its normalized score.\n",
    "    \"\"\"\n",
    "    # Flatten and normalize scores within each group\n",
    "    ingredient_scores = {}\n",
    "    for group, ingredients in ranked_ingredients.items():\n",
    "        scores = np.array([score for _, score in ingredients]).reshape(-1, 1)\n",
    "        scaler = MinMaxScaler()\n",
    "        normalized_scores = scaler.fit_transform(scores).flatten()\n",
    "        for (ingredient, _), norm_score in zip(ingredients, normalized_scores):\n",
    "            ingredient_scores[ingredient] = norm_score\n",
    "    \n",
    "    def score_function(ingredient):\n",
    "        \"\"\"\n",
    "        Returns the normalized score of the given ingredient based on the ranked ingredients.\n",
    "\n",
    "        Parameters:\n",
    "        ingredient (str): The ingredient to look up.\n",
    "\n",
    "        Returns:\n",
    "        float: The normalized score of the ingredient, or 'error' if the ingredient is not found.\n",
    "        \"\"\"\n",
    "        return ingredient_scores.get(ingredient, 'ERROR: Ingredient not found')\n",
    "    \n",
    "    return score_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_function = create_preference_score_function(negotiated_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_function('Bitter chocolate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_child_weight_complex(child, preferences, utility_scores, historical_votes, fairness_index, use_gini=True, use_utility=True, use_historical=True):\n",
    "    \n",
    "    # Count likes, neutrals, and dislikes\n",
    "    total_likes = len(preferences[\"likes\"])\n",
    "    total_neutrals = len(preferences[\"neutral\"])\n",
    "    total_dislikes = len(preferences[\"dislikes\"])\n",
    "    \n",
    "    # Dynamic merit weight adjustment based on utility scores.\n",
    "    child_merit_weight = 1\n",
    "    if use_utility:\n",
    "        child_merit_weight += utility_scores.get(child, 0)\n",
    "    \n",
    "    # Calculate raw weights for each category\n",
    "    likes_weight = total_likes * child_merit_weight\n",
    "    neutral_weight = total_neutrals * child_merit_weight\n",
    "    dislikes_weight = total_dislikes * child_merit_weight\n",
    "\n",
    "    # Normalize weights to sum to 1\n",
    "    total_weight = likes_weight + neutral_weight + dislikes_weight\n",
    "    likes_weight /= total_weight\n",
    "    neutral_weight /= total_weight\n",
    "    dislikes_weight /= total_weight\n",
    "\n",
    "    # Collect all weights across all children if Gini adjustment is used\n",
    "    if use_gini:\n",
    "        all_weights = [likes_weight, neutral_weight, dislikes_weight]\n",
    "        for other_child in historical_votes:\n",
    "            if other_child != child:\n",
    "                other_likes = len(preferences[other_child][\"likes\"])\n",
    "                other_neutrals = len(preferences[other_child][\"neutral\"])\n",
    "                other_dislikes = len(preferences[other_child][\"dislikes\"])\n",
    "                other_child_merit_weight = 1 + utility_scores.get(other_child, 0) if use_utility else 1\n",
    "                all_weights += [\n",
    "                    other_likes * other_child_merit_weight,\n",
    "                    other_neutrals * other_child_merit_weight,\n",
    "                    other_dislikes * other_child_merit_weight\n",
    "                ]\n",
    "\n",
    "        # Calculate the Gini coefficient across all children\n",
    "        gini = calculate_gini(all_weights)\n",
    "    else:\n",
    "        gini = 0\n",
    "\n",
    "    # Update fairness index for the child\n",
    "    if use_gini:\n",
    "        fairness_index[child] = (fairness_index.get(child, 0) + gini) / 2\n",
    "    \n",
    "    # Adjust weights based on fairness index if historical and Gini adjustments are used\n",
    "    if use_historical:\n",
    "        historical_influence = historical_votes.get(child, 0)\n",
    "        fairness_adjustment = 1 - fairness_index.get(child, 0)\n",
    "        likes_weight *= fairness_adjustment\n",
    "        neutral_weight *= fairness_adjustment\n",
    "        dislikes_weight *= fairness_adjustment\n",
    "\n",
    "    # Normalize again to ensure they sum to 1 after adjustment\n",
    "    total_weight = likes_weight + neutral_weight + dislikes_weight\n",
    "    likes_weight /= total_weight\n",
    "    neutral_weight /= total_weight\n",
    "    dislikes_weight /= total_weight\n",
    "\n",
    "    return {\n",
    "        'likes': likes_weight,\n",
    "        'neutral': neutral_weight,\n",
    "        'dislikes': dislikes_weight\n",
    "    }\n",
    "\n",
    "def calculate_gini(weights):\n",
    "    # Gini coefficient calculation\n",
    "    mean_weight = sum(weights) / len(weights)\n",
    "    differences_sum = sum(abs(i - j) for i in weights for j in weights)\n",
    "    gini = differences_sum / (2 * len(weights) ** 2 * mean_weight)\n",
    "    return gini\n",
    "\n",
    "def negotiate_ingredients_complex(preferences, ingredient_df, seed):\n",
    "    \"\"\"\n",
    "    Negotiates and ranks ingredients based on provided votes and availability with additional functionality.\n",
    "\n",
    "    Parameters:\n",
    "    preferences (dict): Dictionary with ingredient names as keys and preference scores as values.\n",
    "    ingredient_df (DataFrame): DataFrame containing ingredient information with one-hot encoded groups.\n",
    "    seed (int): Seed for random number generation.\n",
    "\n",
    "    Returns:\n",
    "    dict: Negotiated ingredients grouped and sorted by votes with additional checks.\n",
    "    dict: Unavailable ingredients.\n",
    "    \"\"\"\n",
    "    # Define the ingredient groups as columns in the one-hot encoded DataFrame\n",
    "    ingredient_groups = ['Group A veg', 'Group A fruit', 'Group BC', 'Group D', 'Group E', 'Bread', 'Confectionary']\n",
    "    \n",
    "    feedback = {}  # Placeholder for feedback data\n",
    "    \n",
    "    # Collect votes and unavailable ingredients for all ingredients\n",
    "    votes, unavailable_ingredients = collect_weighted_votes(preferences, ingredient_df, calculate_child_weight_complex, feedback, seed)\n",
    "    \n",
    "    # Initialize category votes dictionary with ingredient groups\n",
    "    negotiated_ingredients = {group: {} for group in ingredient_groups}\n",
    "    \n",
    "    # Map ingredients to their groups for efficient lookup\n",
    "    ingredient_to_groups = {ingredient: group for group in ingredient_groups for ingredient in ingredient_df[ingredient_df[group] == 1]['Category7']}\n",
    "    \n",
    "    # Collect votes for each ingredient group\n",
    "    for ingredient, vote in votes.items():\n",
    "        if ingredient not in unavailable_ingredients:\n",
    "            group = ingredient_to_groups.get(ingredient)\n",
    "            if group:\n",
    "                negotiated_ingredients[group][ingredient] = vote\n",
    "\n",
    "    # Handle Misc category\n",
    "    misc_df = ingredient_df[(ingredient_df[ingredient_groups].sum(axis=1) == 0)]\n",
    "    misc_votes = {ingredient: votes[ingredient] for ingredient in misc_df['Category7'].tolist() if ingredient in votes and ingredient not in unavailable_ingredients}\n",
    "    negotiated_ingredients['Misc'] = misc_votes\n",
    "\n",
    "    # Sort and balance the top 10% ingredients\n",
    "    for group, group_votes in negotiated_ingredients.items():\n",
    "        sorted_ingredients = sorted(group_votes.items(), key=lambda item: item[1], reverse=True)\n",
    "        top_10_percent = sorted_ingredients[:max(1, len(sorted_ingredients) // 10)]\n",
    "\n",
    "        # Ensure no child has all their dislikes in the top 10%\n",
    "        for child, pref in preferences.items():\n",
    "            dislikes_in_top_10 = set(pref['dislikes']).intersection(dict(top_10_percent).keys())\n",
    "            if len(dislikes_in_top_10) == len(top_10_percent):\n",
    "                for dislike in dislikes_in_top_10:\n",
    "                    group_votes[dislike] -= 1  # Penalize disliked items slightly\n",
    "                    sorted_ingredients = sorted(group_votes.items(), key=lambda item: item[1], reverse=True)\n",
    "                    top_10_percent = sorted_ingredients[:max(1, len(sorted_ingredients) // 10)]\n",
    "        \n",
    "        # Update the sorted ingredients in the negotiated_ingredients dictionary\n",
    "        negotiated_ingredients[group] = dict(sorted_ingredients)\n",
    "    \n",
    "    return negotiated_ingredients, unavailable_ingredients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import copy\n",
    "from models.preferences.data_utils import get_child_data, initialize_child_preference_data\n",
    "from utils.process_data import get_data\n",
    "from models.preferences.prediction import PreferenceModel\n",
    "from models.preferences.voting import IngredientNegotiator\n",
    "from models.preferences.sentiment_analysis import SentimentAnalyzer\n",
    "\n",
    "# Set the logging level to CRITICAL to turn off logging\n",
    "logging.basicConfig(level=logging.CRITICAL, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "seed = 423\n",
    "\n",
    "ingredient_df = get_data(\"data.csv\")\n",
    "child_feature_data = get_child_data()\n",
    "child_preference_data = initialize_child_preference_data(child_feature_data, ingredient_df, split=0.5, seed=seed, plot_graphs=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting\n",
    "Predictor = PreferenceModel(ingredient_df, child_feature_data, child_preference_data, apply_SMOTE=True, seed=seed)\n",
    "updated_known_and_predicted_preferences = Predictor.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Negotiate the ingredients\n",
    "previous_feedback = {}\n",
    "previous_fairness_index = {}\n",
    "previous_utility = {}\n",
    "\n",
    "Negotiator = IngredientNegotiator(seed, ingredient_df, updated_known_and_predicted_preferences, previous_feedback, previous_fairness_index, previous_utility)\n",
    "\n",
    "# Simple\n",
    "negotiated_ingredient_order_simple, unavailable_ingredients_simple = Negotiator.negotiate_ingredients_simple()\n",
    "preference_score_function_simple = Negotiator.create_preference_score_function(negotiated_ingredient_order_simple)\n",
    "\n",
    "# Complex\n",
    "negotiated_ingredient_order_complex, unavailable_ingredients_complex = Negotiator.negotiate_ingredients_complex()\n",
    "preference_score_function_complex = Negotiator.create_preference_score_function(negotiated_ingredient_order_complex)\n",
    "\n",
    "Negotiator.close(log_file=\"Gini.json\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedback\n",
    "menu_plan = ['Wheat bread and rolls white (refined flour)', 'Potatoes', 'Sour cream plain', 'Trouts', 'Pepper', 'Cauliflowers']\n",
    "from models.preferences.sentiment_analysis import SentimentAnalyzer\n",
    "Sentiment = SentimentAnalyzer(child_preference_data, menu_plan, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "updated_true_preferences_with_feedback, accuracy, feedback_given = Sentiment.get_sentiment_and_update_data(plot_confusion_matrix=False)\n",
    "\n",
    "# Sentiment.display_feedback_changes(child_preference_data)\n",
    "# Sentiment.display_incorrect_feedback_changes()\n",
    "\n",
    "print(\"Sentiment Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting\n",
    "Predictor = PreferenceModel(ingredient_df, child_feature_data, updated_true_preferences_with_feedback, apply_SMOTE=False, seed=seed)\n",
    "updated_known_and_predicted_preferences = Predictor.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_given\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_random_indices(n, mean_length, std_dev_length):\n",
    "    \n",
    "    # Generate a random length for the list\n",
    "    length = int(np.random.normal(loc=mean_length, scale=std_dev_length))\n",
    "    \n",
    "    # Clamp the length to ensure it is within a reasonable range [0, n]\n",
    "    length = max(0, min(n, length))\n",
    "    \n",
    "    # Generate a list of unique random indices of the specified length\n",
    "    indices = np.random.choice(n, size=length, replace=False)\n",
    "    \n",
    "    return indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negotiated = {\n",
    "    'Group A veg': {\n",
    "        'Asparagus': 136, 'Aubergines': 122, 'Avocados': 144, 'Beetroots': 44,\n",
    "        'Broccoli': 84, 'Brussels sprouts': 92, 'Carrots': 150, 'Cauliflowers': 98,\n",
    "        'Celeries': 72, 'Chili peppers': 150, 'Common bean sprouts': 68, 'Common mushrooms': 56,\n",
    "        'Courgettes': 136, 'Curly kales': 44, 'Garlic': 82, 'Jerusalem artichokes': 56,\n",
    "        'Leeks': 136, 'Lettuces (generic)': 66, 'Onions': 112\n",
    "    },\n",
    "    'Group A fruit': {\n",
    "        'Apples': 150, 'Blueberries': 124, 'Cherries and similar-': 150, 'Common banana': 150,\n",
    "        'Grapefruits': 62, 'Kiwi fruits (green red yellow)': 150, 'Limes': 122, 'Mango': 150,\n",
    "        'Nectarines': 150, 'Oranges sweet': 150, 'Papayas': 150, 'Passionfruits': 74,\n",
    "        'Pears': 150, 'Pineapples': 150, 'Plums': 150, 'Raspberries': 150,\n",
    "        'Rhubarbs': 124, 'Strawberries': 150, 'Table grapes': 150\n",
    "    },\n",
    "    'Group BC': {\n",
    "        'Almonds': 32, 'Anchovies': 122, 'Bacon': 90, 'Brazil nuts': 32,\n",
    "        'Breakfast-type sausage': 88, 'Cashew nuts': 32, 'Chicken fresh meat': 92,\n",
    "        'Chickpeas (dry)': 96, 'Coalfish': 102, 'Coconuts': 150, 'Cod': 94,\n",
    "        'Cow ox or bull fresh meat': 88, 'Deer red fresh meat': 82, 'Duck fresh meat': 82,\n",
    "        'Edible crab': 102, 'Eggs': 84, 'Fish fingers breaded': 100, 'Frankfurter sausage': 88,\n",
    "        'Haddock': 96\n",
    "    },\n",
    "    'Group D': {\n",
    "        'Buckwheat': 32, 'Couscous': 120, 'New potatoes': 106, 'Noodles': 112,\n",
    "        'Pasta plain (not stuffed) uncooked': 110, 'Pasta wholemeal': 102, 'Potatoes': 94,\n",
    "        'Rice grain': 94, 'Rice grain brown': 86, 'Rice grain long-grain': 90, 'Sweet potatoes': 150\n",
    "    },\n",
    "    'Group E': {\n",
    "        'Butter': 104, 'Cheese cheddar': 110, 'Cow milk semi skimmed (half fat)': 66,\n",
    "        'Cow milk skimmed (low fat)': 62, 'Cow milk whole': 70, 'Cream plain': 80,\n",
    "        'Creme fraiche cheese': 84, 'Mascarpone': 80, 'Mozzarella': 86, 'Parmesan': 106,\n",
    "        'Sour cream': 68, 'Traditional margarine': 102, 'Yoghurt cow milk flavoured': 96,\n",
    "        'Yoghurt cow milk plain': 68\n",
    "    },\n",
    "    'Bread': {\n",
    "        'Wheat bread and rolls brown or wholemeal': 64,\n",
    "        'Wheat bread and rolls white (refined flour)': 96\n",
    "    },\n",
    "    'Confectionary': {\n",
    "        'Bitter chocolate': 92, 'Chocolate coated confectionery': 94, 'Honey': 110,\n",
    "        'White chocolate': 94, 'White sugar': 94\n",
    "    },\n",
    "    'Misc': {\n",
    "        'Basil': 120, 'Corianders': 120, 'Olive oil': 128, 'Oregano': 118,\n",
    "        'Palm oil/fat': 104, 'Parsley': 122, 'Rape seed oil edible': 104, 'Rosemary': 114,\n",
    "        'Sunflower seed oil edible': 106, 'Wheat flour white': 64, 'Wheat wholemeal flour': 60\n",
    "    }\n",
    "}\n",
    "\n",
    "unavailable = {'Cucumber'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Dict, List, Set, Optional\n",
    "\n",
    "class RandomMenuGenerator:\n",
    "    def __init__(self, seed: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Initializes the RandomMenuGenerator with an optional seed for randomization.\n",
    "\n",
    "        :param seed: An optional seed for random number generation.\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "        self.random = random.Random(seed)\n",
    "        self.generated_count = 1\n",
    "        self.groups_to_remove_from = ['Group A veg', 'Group A fruit', 'Group BC', 'Group D', 'Group E']\n",
    "\n",
    "    def initialize_ingredient_in_groups(self, negotiated: Dict[str, Dict[str, float]], unavailable: Optional[Set[str]]) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the ingredients and their scores for each group, excluding unavailable ingredients,\n",
    "        and normalizes the scores. Also makes a copy of the original ingredients and scores to reset after 10 generations.\n",
    "\n",
    "        :param negotiated: A dictionary where keys are ingredient groups and values are dictionaries of ingredients with their scores.\n",
    "        :param unavailable: A set of unavailable ingredients.\n",
    "        \"\"\"\n",
    "        self.negotiated = negotiated\n",
    "        self.unavailable = unavailable or set()\n",
    "        self.ingredient_groups = list(negotiated.keys())\n",
    "\n",
    "        # Initialize dictionaries\n",
    "        self.ingredients_in_groups = {group: [] for group in self.ingredient_groups}\n",
    "        self.ingredients_scores = {group: [] for group in self.ingredient_groups}\n",
    "        self.total_scores = {group: 0 for group in self.ingredient_groups}\n",
    "\n",
    "        # Populate dictionaries and normalize scores\n",
    "        for group, items in self.negotiated.items():\n",
    "            for ingredient, score in items.items():\n",
    "                if ingredient not in self.unavailable:\n",
    "                    self.ingredients_in_groups[group].append(ingredient)\n",
    "                    self.ingredients_scores[group].append(score)\n",
    "                    self.total_scores[group] += score\n",
    "\n",
    "        # Normalize scores initially\n",
    "        self.normalize_scores()\n",
    "\n",
    "        # Make a copy of the original ingredients list and scores to reset after 10 generations\n",
    "        self.original_ingredients_in_groups = {group: items.copy() for group, items in self.ingredients_in_groups.items()}\n",
    "        self.original_ingredients_scores = {group: scores.copy() for group, scores in self.ingredients_scores.items()}\n",
    "        self.original_total_scores = self.total_scores.copy()\n",
    "\n",
    "    def normalize_scores(self) -> None:\n",
    "        \"\"\"\n",
    "        Normalizes the scores of the ingredients within each group to ensure they sum up to 1.\n",
    "        \"\"\"\n",
    "        self.normalized_scores = {group: [] for group in self.ingredient_groups}\n",
    "        for group in self.ingredient_groups:\n",
    "            total_score = self.total_scores[group]\n",
    "            if total_score > 0:\n",
    "                for score in self.ingredients_scores[group]:\n",
    "                    self.normalized_scores[group].append(score / total_score)\n",
    "            else:\n",
    "                self.normalized_scores[group] = [1 / len(self.ingredients_scores[group])] * len(self.ingredients_scores[group])\n",
    "\n",
    "    def generate_random_item(self, group: str, num_items: int = 1) -> List[str]:\n",
    "        \"\"\"\n",
    "        Generates a list of random items from a specified group based on the normalized scores.\n",
    "\n",
    "        :param group: The ingredient group to sample from.\n",
    "        :param num_items: The number of items to sample.\n",
    "        :return: A list of randomly selected ingredients.\n",
    "        :raises ValueError: If there are not enough ingredients in the group to sample the requested number of items.\n",
    "        \"\"\"\n",
    "        if len(self.ingredients_in_groups[group]) < num_items:\n",
    "            raise ValueError(f\"Not enough ingredients in group {group} to sample {num_items} items\")\n",
    "        items = self.ingredients_in_groups[group]\n",
    "        weights = self.normalized_scores[group]\n",
    "        item = self.random.choices(items, weights=weights, k=num_items)\n",
    "        return item\n",
    "    \n",
    "    def generate_random_menu(self, negotiated: Dict[str, Dict[str, float]], unavailable: Optional[Set[str]] = None, groups_to_remove_from: Optional[List[str]] = None) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Generates a random menu by selecting one random item from each ingredient group. If 10 menus have been generated,\n",
    "        it resets the ingredients.\n",
    "\n",
    "        :param negotiated: A dictionary where keys are ingredient groups and values are dictionaries of ingredients with their scores.\n",
    "        :param unavailable: A set of unavailable ingredients.\n",
    "        :param groups_to_remove_from: List of groups to remove selected items from.\n",
    "        :return: A dictionary representing the generated menu.\n",
    "        \"\"\"\n",
    "        self.initialize_ingredient_in_groups(negotiated, unavailable)\n",
    "        \n",
    "        if self.generated_count >= 11:\n",
    "            print(\"Generated 10 meal plans, resetting ingredients.\")\n",
    "            self.reset_ingredients()\n",
    "        \n",
    "        if groups_to_remove_from is None:\n",
    "            groups_to_remove_from = self.groups_to_remove_from\n",
    "        \n",
    "        menu = {}\n",
    "        for group in self.ingredient_groups:\n",
    "            try:\n",
    "                item = self.generate_random_item(group, 1)[0]\n",
    "                menu[group] = item\n",
    "                # Remove chosen ingredients from the specified groups\n",
    "                if group in groups_to_remove_from:\n",
    "                    index = self.ingredients_in_groups[group].index(item)\n",
    "                    self.total_scores[group] -= self.ingredients_scores[group][index]\n",
    "                    del self.ingredients_in_groups[group][index]\n",
    "                    del self.ingredients_scores[group][index]\n",
    "                    self.normalize_scores()\n",
    "            except ValueError as e:\n",
    "                print(f\"Error generating item for group {group}: {e}\")\n",
    "                self.reset_ingredients()\n",
    "                return self.generate_random_menu(negotiated, unavailable, groups_to_remove_from)\n",
    "        \n",
    "        print(\"\\nGenerated meal plan number\", self.generated_count)\n",
    "        self.generated_count += 1\n",
    "        return menu\n",
    "    \n",
    "    def reset_ingredients(self) -> None:\n",
    "        \"\"\"\n",
    "        Resets the ingredients and their scores to the original state and normalizes the scores.\n",
    "        \"\"\"\n",
    "        self.ingredients_in_groups = {group: items.copy() for group, items in self.original_ingredients_in_groups.items()}\n",
    "        self.ingredients_scores = {group: scores.copy() for group, scores in self.original_ingredients_scores.items()}\n",
    "        self.total_scores = self.original_total_scores.copy()\n",
    "        self.normalize_scores()\n",
    "        self.generated_count = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_generator = RandomMenuGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_generator.generate_random_menu(negotiated, unavailable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 17:39:50.599166: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-25 17:39:50.736252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 17:39:53.274648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Level not an integer or a valid string: <function info at 0x7f1d6b219a20>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreferences\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmenu_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomMenuGenerator\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m---> 16\u001b[0m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasicConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(asctime)s\u001b[39;49;00m\u001b[38;5;124;43m - \u001b[39;49m\u001b[38;5;132;43;01m%(levelname)s\u001b[39;49;00m\u001b[38;5;124;43m - \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m weight_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     19\u001b[0m iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m \n",
      "File \u001b[0;32m~/anaconda3/envs/masterEnv/lib/python3.10/logging/__init__.py:2059\u001b[0m, in \u001b[0;36mbasicConfig\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   2057\u001b[0m level \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   2058\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2059\u001b[0m     \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetLevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m   2061\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(kwargs\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/anaconda3/envs/masterEnv/lib/python3.10/logging/__init__.py:1452\u001b[0m, in \u001b[0;36mLogger.setLevel\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetLevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, level):\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;124;03m    Set the logging level of this logger.  level must be an int or a str.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m=\u001b[39m \u001b[43m_checkLevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanager\u001b[38;5;241m.\u001b[39m_clear_cache()\n",
      "File \u001b[0;32m~/anaconda3/envs/masterEnv/lib/python3.10/logging/__init__.py:201\u001b[0m, in \u001b[0;36m_checkLevel\u001b[0;34m(level)\u001b[0m\n\u001b[1;32m    199\u001b[0m     rv \u001b[38;5;241m=\u001b[39m _nameToLevel[level]\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLevel not an integer or a valid string: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m                     \u001b[38;5;241m%\u001b[39m (level,))\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rv\n",
      "\u001b[0;31mTypeError\u001b[0m: Level not an integer or a valid string: <function info at 0x7f1d6b219a20>"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models.preferences.data_utils import (\n",
    "    get_child_data,\n",
    "    initialize_child_preference_data,\n",
    "    print_preference_difference_and_accuracy,\n",
    ")\n",
    "from utils.process_data import get_data\n",
    "from models.preferences.prediction import PreferenceModel\n",
    "from models.preferences.voting import IngredientNegotiator\n",
    "from models.preferences.sentiment_analysis import SentimentAnalyzer\n",
    "from models.preferences.menu_generator import RandomMenuGenerator\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "weight_function='simple'\n",
    "iterations=500 \n",
    "seed=None\n",
    "\n",
    "\"\"\"Main function to run the preference prediction and negotiation pipeline.\"\"\"\n",
    "\n",
    "ingredient_df = get_data(\"data.csv\")\n",
    "child_feature_data = get_child_data()\n",
    "child_preference_data = initialize_child_preference_data(\n",
    "    child_feature_data, ingredient_df, split=0.5, seed=seed, plot_graphs=False\n",
    ")\n",
    "\n",
    "# Lists to store accuracy values\n",
    "prediction_accuracies = []\n",
    "prediction_std = []\n",
    "sentiment_accuracies = []\n",
    "\n",
    "# Initialize menu generator\n",
    "menu_generator = RandomMenuGenerator(seed=seed)\n",
    "\n",
    "# Initial Prediction of Preferences\n",
    "predictor = PreferenceModel(\n",
    "    ingredient_df, child_feature_data, child_preference_data, apply_SMOTE=True, seed=seed\n",
    ")\n",
    "updated_known_and_predicted_preferences = predictor.run_pipeline()\n",
    "\n",
    "accuracy, std_dev = print_preference_difference_and_accuracy(\n",
    "    child_preference_data, updated_known_and_predicted_preferences, summary_only=True\n",
    ")\n",
    "\n",
    "prediction_accuracies.append(accuracy)\n",
    "prediction_std.append(std_dev)\n",
    "\n",
    "previous_feedback = {}\n",
    "previous_fairness_index = {}\n",
    "previous_utility = {}\n",
    "\n",
    "for i in range(iterations):\n",
    "    logging.info(f\"Iteration {i + 1}\")\n",
    "\n",
    "    # Initial Negotiation of Ingredients\n",
    "    negotiator = IngredientNegotiator(\n",
    "        seed, ingredient_df, updated_known_and_predicted_preferences, previous_feedback, previous_fairness_index, previous_utility\n",
    "    )\n",
    "\n",
    "    if weight_function == \"simple\":\n",
    "        # Simple\n",
    "        negotiated, unavailable = negotiator.negotiate_ingredients_simple()\n",
    "    elif weight_function == \"complex\":\n",
    "        # Complex\n",
    "        negotiated, unavailable = negotiator.negotiate_ingredients_complex()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid weight function\")\n",
    "\n",
    "    # # Close negotiator to get initial gini stats on voting\n",
    "    # negotiator.close(log_file=f\"Gini_iteration_{i + 1}.json\")\n",
    "\n",
    "    # Generate random menu\n",
    "    menu_plan = menu_generator.generate_random_menu(negotiated, unavailable)\n",
    "\n",
    "    # Sentiment analysis and get updated preference list\n",
    "    sentiment_analyzer = SentimentAnalyzer(\n",
    "        child_preference_data, menu_plan, seed=seed\n",
    "    )\n",
    "    (\n",
    "        updated_true_preferences_with_feedback,\n",
    "        sentiment_accuracy,\n",
    "        feedback_given,\n",
    "    ) = sentiment_analyzer.get_sentiment_and_update_data(plot_confusion_matrix=False)\n",
    "\n",
    "    logging.info(f\"Iteration {i + 1} - Sentiment Accuracy: {sentiment_accuracy}\")\n",
    "    sentiment_accuracies.append(sentiment_accuracy)\n",
    "\n",
    "    # Update predictor with new preferences\n",
    "    predictor = PreferenceModel(\n",
    "        ingredient_df, child_feature_data, updated_true_preferences_with_feedback, apply_SMOTE=True, seed=seed\n",
    "    )\n",
    "    updated_known_and_predicted_preferences = predictor.run_pipeline()\n",
    "\n",
    "    accuracy, std_dev = print_preference_difference_and_accuracy(\n",
    "        child_preference_data, updated_known_and_predicted_preferences, summary_only=True\n",
    "    )\n",
    "    logging.info(f\"Iteration {i + 1} - Prediction Accuracy: {accuracy}\")\n",
    "    prediction_accuracies.append(accuracy)\n",
    "    prediction_std.append(std_dev)\n",
    "\n",
    "    previous_feedback = feedback_given\n",
    "    previous_fairness_index = {}\n",
    "    previous_utility = {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(prediction_accuracies, prediction_std, sentiment_accuracies, iterations):\n",
    "    \"\"\"Function to plot the accuracies and standard deviations over iterations.\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(1, iterations + 2), prediction_accuracies, marker='o', label='Prediction Accuracy')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Prediction Accuracy per Iteration')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(1, iterations + 1), sentiment_accuracies, marker='o', label='Sentiment Accuracy', color='orange')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Sentiment Accuracy per Iteration')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(1, iterations + 2), prediction_std, marker='o', label='Prediction Std', color='green')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Standard Deviation')\n",
    "    plt.title('Prediction Standard Deviation per Iteration')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(prediction_accuracies, prediction_std, sentiment_accuracies, iterations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
